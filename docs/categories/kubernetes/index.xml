<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on 老麦的书房</title><link>https://tangx.in/categories/kubernetes/</link><description>Recent content in kubernetes on 老麦的书房</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 10 Jan 2023 10:28:03 +0800</lastBuildDate><atom:link href="https://tangx.in/categories/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>k8sailor 服务管理平台 - 01. 使用 k3s 快速搭建项目环境</title><link>https://tangx.in/posts/books/k8sailor/chapter01/01-install-k3s-cluster/</link><pubDate>Tue, 10 Jan 2023 10:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/k8sailor/chapter01/01-install-k3s-cluster/</guid><description>《k8sailor》 - 01. 使用 k3s 快速搭建项目环境 安装 k3s 安装过程参考 https://tangx.in/2021/06/07/k3s-architecture-single-server/ k3s 集群版本为 v1.21.4。 因此 k8s client-go sdk 的版本也需要安装对应版本 1 2 3 4 5 6 7 8 9 10 11 # curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - [INFO] Finding release for channel stable [INFO] Using v1.21.4+k3s1 as release [INFO] Downloading hash http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/sha256sum-amd64.txt [INFO] Downloading binary http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/k3s [INFO] Verifying binary download [INFO] Installing k3s to /usr/local/bin/k3s ... 省略 初始化环境 通过命令创建一些工作负载， 以便后续 k8s api 调用</description></item><item><title>k8sailor 服务管理平台 - 01. 使用 k3s 快速搭建项目环境</title><link>https://tangx.in/posts/books/k8sailor/chapter01/02-design-cobra-command/</link><pubDate>Tue, 10 Jan 2023 10:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/k8sailor/chapter01/02-design-cobra-command/</guid><description>使用 cobra 管理命令与参数 tag: https://github.com/tangx/k8sailor/tree/feat/01-cobra-command 为了更加方便的管理配置文件的来源， 这里使用 cobra 进行命令行构建 效果如下 1 2 3 4 5 6 7 8 9 cd cmd/k8sailor &amp;amp;&amp;amp; go run . k8s 管理平台 Usage: k8sailor [flags] Flags: --config string k8s 配置授权文件 (default &amp;#34;./k8sconfig/config.yml&amp;#34;) -h, --help help for k8sailor 编码 变量管理 在 cmd/k8sailor/global 目录中管理 全局 变量。 其中，定义一个 CmdFlag 结构体管理所有 cobra flags。 1 2 3 4 5 6 7 type CmdFlags struct { Config string `flag:&amp;#34;config&amp;#34; usage:&amp;#34;k8s</description></item><item><title>《kubebuilder 从零开始实战》 - 01. 使用 kuberbuilder 初始化项目</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/01-kubebuilder-init-project/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/01-kubebuilder-init-project/</guid><description>使用 kuberbuilder 初始化项目 代码在: https://github.com/tangx/kubebuilder-zero-to-one 1 2 kubebuilder init --domain tangx.in kubebuilder create api --group myapp --version v1 --kind Redis 1 2 3 4 5 6 7 8 9 apiVersion: myapp.tangx.in/v1 kind: Redis metadata: name: my-op-redis spec: replicas: 1 port: 3333 1 2 3 4 5 # 安装 make install # 卸载 make uninstall 查看 crd 1 2 3 k get crd |grep tangx.in redis.myapp.tangx.in 2021-11-19T06:16:43Z</description></item><item><title>《kubebuilder 从零开始实战》 - 02. 定义对象 CRD 字段， 实现第一个 DEMO</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/02-simplest-redis-crd/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/02-simplest-redis-crd/</guid><description>定义对象 CRD 字段， 实现第一个 DEMO 代码在: https://github.com/tangx/kubebuilder-zero-to-one 定义 CRD Redis 对象字段 在 /api/v1/redis_types.go 中， 增加 Replicas 和 Port 字段。 1 2 3 4 5 6 7 8 9 type RedisSpec struct { // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run &amp;#34;make&amp;#34; to regenerate code after modifying this file // Foo is an example field of Redis. Edit redis_types.go to remove/update // Foo string `json:&amp;#34;foo,omitempty&amp;#34;` Replicas int `json:&amp;#34;replicas,omitempty&amp;#34;` Port int32 `json:&amp;#34;port,omitempty&amp;#34;` } 这个 RedisSpec 对应 /deploy/my-op-redis.yml 中的 spec 1 2 3 4 5 6 7 8 9 10 apiVersion: myapp.tangx.in/v1 kind: Redis metadata: name: my-op-redis spec: replicas: 1 port: 3333 编码 Reconcile 调谐逻辑 在 /controllers/redis_controller.go 中编码 R</description></item><item><title>《kubebuilder 从零开始实战》 - 03. 优化配置 发布 crd controller 到集群</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/03-deploy-crd-controller/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/03-deploy-crd-controller/</guid><description>优化配置 发布 crd controller 到集群 设置 docker server 网络代理， 避免编译的时候下载所依赖的 gcr.io 镜像失败。 参考文章 设置 docker server 网路代理 修改 Makefile, 设置默认 image name 1 2 3 4 VERSION ?= v$(shell cat .version) # Image URL to use all building/pushing image targets IMG ?= cr.docker.tangx.in/jtredis/controller:$(VERSION) 修改镜像 pull 策略。 在 /config/manager/manager.yaml 配置文件中， 添加 imagePullPolicy 策略。 由于本地开发， 并不准备上传到云上， 所以设置为 IfNotPresent。 1 2</description></item><item><title>《kubebuilder 从零开始实战》 - 04. 使用注解完整字段值约束</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/04-filed-validation-by-comment/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/04-filed-validation-by-comment/</guid><description>使用注解完整字段值约束 代码在: https://github.com/tangx/kubebuilder-zero-to-one 在 /api/v1/redis_types.go 中，使用注解完成字段值约束。 约束条件必须以 //+kubebuilder:validation:&amp;lt;METHOD&amp;gt;:=&amp;lt;VALUE&amp;gt; 为格式， 符号之间 没有空格。 约束条件必须 紧邻 字段， 且在字段上方。 https://book.kubebuilder.io/reference/markers/crd-validation.html 1 2 3 4 5 6 7 8 9 10 type RedisSpec struct { // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run &amp;#34;make&amp;#34; to regenerate code after modifying this file Replicas int `json:&amp;#34;replicas,omitempty&amp;#34;` //+kubebuilder:validation:Minimum:=1234 //+kubebuilder:validation:Maximum:=54321 Port int32 `json:&amp;#34;port,omitempty&amp;#34;` } 重新编译安装 1 make install 使用命令查看查看 1 2 3 4 5 6 7</description></item><item><title>《kubebuilder 从零开始实战》 - 05. 使用注解完整字段值约束</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/05-filed-validation-by-webhook/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/05-filed-validation-by-webhook/</guid><description>通过 webhook 进行字段验证 代码在: https://github.com/tangx/kubebuilder-zero-to-one 通过 kubebuilder 生成代码 1 2 3 4 5 # 创建 api kubebuilder create api --group myapp --version v1 --kind Redis # 创建 api 的 webhook kubebuilder create webhook --group myapp --version v1 --kind Redis --defaulting --programmatic-validation 增加 webhook 条件 在 /api/v1/redis_webhook.go 中增加检查条件。 检查 webhook 被触发有三个条件 Create / Update / Delete 时间节点, 分别对应三个方法。 如下是 创建时检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (r *Redis) ValidateCreate() error { redislog.Info(&amp;#34;validate create&amp;#34;, &amp;#34;name&amp;#34;, r.Name) // 条件判断 if</description></item><item><title>《kubebuilder 从零开始实战》 - 06. 使用 Operator 创建并发布一个 Pod</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/06-create-pod-by-redis-operator/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/06-create-pod-by-redis-operator/</guid><description>使用 Operator 创建并发布一个 Pod 代码在: https://github.com/tangx/kubebuilder-zero-to-one 1. 组装 k8s api 创建 pod 创建 /controllers/helper 目录， 这里面的代码实现 k8s Workloads 的创建。 具体实现就是封装 k8s workloads 的 api 对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // CreateRedis 创建 redis pod func CreateRedisPod2(ctx context.Context, client client.Client, config *appv1.Redis) error { pod := &amp;amp;corev1.Pod{} pod.Name = config.Name pod.Namespace = config.Namespace pod.Spec.Containers = []corev1.Container{ { Name: config.Name, Image: config.Spec.Image, ImagePullPolicy: corev1.PullIfNotPresent, Ports: []corev1.ContainerPort{ { ContainerPort: config.Spec.Port, }, }, }, } // ctx := context.Background() return client.Create(ctx, pod) } 补充说明一下，为什么要</description></item><item><title>《kubebuilder 从零开始实战》 - 07.1. 使用 OwnerReference 管理资源父子关系</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/07-1-delete-pod-by-redis-OwnerReference/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/07-1-delete-pod-by-redis-OwnerReference/</guid><description>使用 OwnerReference 管理资源父子关系 代码在: https://github.com/tangx/kubebuilder-zero-to-one https://kubernetes.io/blog/2021/05/14/using-finalizers-to-control-deletion/ 在上一章的代码可以通过如下命令创建一个 redis 实例， 并随即创建一个 Pod 1 ka -f deploy/ 但是在使用如下命令删除 redis 实例时， 虽然命令行界面提示删除成功， 但是创建的 Pod 依旧存在。 1 krm -f deploy/ 其原因是 redis 实例 与 Pod 之间 没有 建立关联关系。 那要如何创建关联关系呢？ 可以参考阅读官方博客，</description></item><item><title>《kubebuilder 从零开始实战》 - 07.2. 使用 finalizers 防止资源被删除</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/07-2-delete-pod-by-finalizers/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/07-2-delete-pod-by-finalizers/</guid><description>使用 finalizers 防止资源被删除 代码在: https://github.com/tangx/kubebuilder-zero-to-one 上一章使用了 OwnerReference 关联 redis instance 和所创建的 Pod， 这里的删除是通过 k8s 内置的关系处理器处理的。 https://kubernetes.io/blog/2021/05/14/using-finalizers-to-control-deletion/ 根据官方博客文档中的阐述， 当一个资源的额 finalizers 没有被清空时， 这个资源将无法被删除。 因此， 本章通过 finalizers 来建立 redis instance 和所创建 pod 的关系， 以及处理删除逻辑 1. 创建 redis instance 与 pod 的关系 在 /controllers/helper/redis_helper.go 通过</description></item><item><title>《kubebuilder 从零开始实战》 - 08. Pod 扩容与缩容</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/08-scale-pod/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/08-scale-pod/</guid><description>Pod 扩容与缩容 代码在: https://github.com/tangx/kubebuilder-zero-to-one 代码分支越来越多 增/删/改 都有了， 于是选择拆分为 3 个分支。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 扩容 func (r *RedisReconciler) increaseReconcile(ctx context.Context, redis *myappv1.Redis) (ctrl.Result, error) { // ... } // 缩容 func (r *RedisReconciler) decreaseReconcile(ctx context.Context, redis *myappv1.Redis) (ctrl.Result, error) { // ... } // 删除 func (r *RedisReconciler) deleteReconcile(ctx context.Context, redis *myappv1.Redis) (ctrl.Result, error) { // ... } 所谓 扩容/缩容， 在通过 finalizers 管理的时候就是 redis.spec.replicas 与 len(redis.finalizers) 的大小比较。 1 2 3 4 // 缩容 if len(redis.Finalizers) &amp;gt;</description></item><item><title>《kubebuilder 从零开始实战》 - 09. 监听 k8s 事件</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/09-watch-k8s-event/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/09-watch-k8s-event/</guid><description>监听 k8s 事件 代码在: https://github.com/tangx/kubebuilder-zero-to-one 之前的代码遗留了一个问题， 当手动通过命令删除 pod 时候， 不会出发 redis.Finalizers 的更新， 也不会重建被删除的 Pod， 实现效果并不好 1 kubectl delete pod pod_name 1. 监听事件 在 /controllers/redis_controller.go 中生成了对象和方法监听 k8s 的事件。 ctrl 创建的 Builder 可以通过 链式 调用方式， 监听多个 k8s 对象的事件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // SetupWithManager sets up the</description></item><item><title>《kubebuilder 从零开始实战》 - 10. 重建被删除的 Pod</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/10-recreate-deleted-pod/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/10-recreate-deleted-pod/</guid><description>重建被删除的 Pod 代码在: https://github.com/tangx/kubebuilder-zero-to-one 之前遗留了一个问题， 直接用命令行删除的 Pod 不能被重建。 这次就来解决它。 首先来整理之前遗留的问题故障点在哪里？ 使用命令 kubectl delete 直接删除 pod 的时候， redis.Finalizers 不会变更， 依旧包含被删除的 pod.Name。 在创建 Pod 的时候， 判断 Pod 是否存在使用的是 redis.Finalizers 提供信息， 而 没有判断 k8s 中真实的情况</description></item><item><title>《kubebuilder 从零开始实战》 - 11. 使用 controllerutil 优化代码</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/11-official-package-optimize/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/11-official-package-optimize/</guid><description>使用 controllerutil 优化代码 代码在: https://github.com/tangx/kubebuilder-zero-to-one 在之前的代码中， 对于 OwnerReference 和 Finalizers 操作我们自己实现了一些方法。 其实这些操作官方已经封好成包了， 开箱即用。 复制 /controllers/helper 保存为 /controllers/helper2。 前者保存手工代码， 后者保存优化代码。 https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/controller/controllerutil Finalizers 操作 之前 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29</description></item><item><title>《kubebuilder 从零开始实战》 - 12. 增加 k8s event 事件支持</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/12-add-event/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/12-add-event/</guid><description>增加 event 事件支持 代码在: https://github.com/tangx/kubebuilder-zero-to-one k8s 官方 controller 都实现了 Events 消息信息， 如下 1 2 3 4 5 6 7 kubectl describe deployment k8s-operator-demo-controller-manager Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 15m deployment-controller Scaled up replica set k8s-operator-demo-controller-manager-75cc59d8ff to 1 Normal ScalingReplicaSet 14m deployment-controller Scaled down replica set k8s-operator-demo-controller-manager-b9d9f7886 to 0 我们自定义的 Operator 同样可以实现。 operator 支持 event 在 /controllers/redis_controller.go 中定义 RedisReconcile 的时候， 添加 EventRecord 字段。 1 2 3 4 5 6 7 8 // RedisReconciler reconciles a Redis object type RedisReconciler struct { client.Client Scheme *runtime.Scheme // 添加事件 EventRecord record.EventRecorder } 在 /main.go 中， 创</description></item><item><title>《kubebuilder 从零开始实战》 - 13. 添加 CRD 对象 Status 状态字段</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/13-add-status/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/13-add-status/</guid><description>添加 CRD 对象 Status 状态字段 代码在: https://github.com/tangx/kubebuilder-zero-to-one 添加 kd 状态字段 在 /api/v1/redis_types.go 的 RedisStatus 中添加需要展示的字段。 这里添加一个副本数量。 1 2 3 4 5 type RedisStatus struct { // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster // Important: Run &amp;#34;make&amp;#34; to regenerate code after modifying this file Replicas int `json:&amp;#34;replicas&amp;#34;` } 偷懒， 没有在创建或删除 pod 时进行精细控制。 而是使用 defer 在 Reconcile 退出的时候进行一次最终的赋值管理。 1 2 3 4 5 6 7 8 9 10 11 12 13</description></item><item><title>《kubebuilder 从零开始实战》 - 14. CRD 支持 kubectl scale 和 kubectl autoscale 命令</title><link>https://tangx.in/posts/books/kubebuilder-zero-to-one/14-kubectl-scale-autoscale-support/</link><pubDate>Mon, 09 Jan 2023 01:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kubebuilder-zero-to-one/14-kubectl-scale-autoscale-support/</guid><description>支持 kubectl scale 和 kubectl autoscale 命令 代码在: https://github.com/tangx/kubebuilder-zero-to-one 在 k8s 自定义资源中有关于 scale 和 hpa 的 subresources 字段， 只有这些字段被定义的时候才能支持 scale 和 autoscale 命令 官方定义如下 https://kubernetes.io/zh/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#scale-subresource 在 kubebuilde 中， 使用 //+kubebuilder:subresource:scale 增加注解， 生成对应的配置。 注意， 未知需要在 //+kubebuilder:subresource:status 下方 1 2 3 //+kubebuilder:object:root=true //+kubebuilder:subresource:status //+kubebuilder:subresource:scale:specpath=.spec.replicas,statuspath=.status.replicas,selectorpath=.status.selector 三个关键字段: specpath: specReplicasPath 指定定制资源内与 scale.spec.replicas 对应的 JSON 路径。 此字段为 必需值 。 只可以使用 .spec 下的 JSON</description></item><item><title>从零开始写 k8s 发布工具 - 1.0. kustz 介绍和设计思想</title><link>https://tangx.in/posts/books/kustz/chapter01/01-introduce/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter01/01-introduce/</guid><description>从零开始写 k8s 发布工具（1） - kustz 介绍和设计思想 介绍 如果要在 Kubernets 发布一个应用， 并对外提供服务， 需要配置诸如 Dep, Ing, Svc 等 Config API。 他们之间又是通过 Label 组合选择而实现的 松耦合。 如果想要这些 Config API 之间的关系更加紧密， 我们可以自己再向上抽象， 通过自己的配置将他们整合在一起。 更重要的是， 我们可以通过这层</description></item><item><title>从零开始写 k8s 发布工具 - 2.1. 模仿 kubectl create 创建 Deployment 样例</title><link>https://tangx.in/posts/books/kustz/chapter02/01-sample-deployment/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter02/01-sample-deployment/</guid><description>2.1. 模仿 kubectl create 创建 Deployment 样例 为了简单， 我们假定所管理的 Deployment 都是 单容器 的。 首先参考 kubectl create 命令 1 $ kubectl create deployment my-dep --image=busybox --replicas 1 --dry-run=client -o yaml 安装 client-go API 访问 client-go https://github.com/kubernetes/client-go 1 $ go get k8s.io/client-go@v0.25.4 这里直接选用最新版本 v0.25.4。 对于其他版本的兼容， 留在以后再做。 定义 Kustz Config 参考 kubectl create 命令， 创建配置文件 kustz.yml 结构如下 1 2 3 4 5 6 7 8 # kustz.yml namespace: demo-demo name: srv-webapp-demo service: name: nginx image: docker.io/library/nginx:alpine</description></item><item><title>从零开始写 k8s 发布工具 - 2.2. 定义字符串创建 Service</title><link>https://tangx.in/posts/books/kustz/chapter02/02-define-strings-to-service/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter02/02-define-strings-to-service/</guid><description>2.2. 定义字符串创建 Service 大家好， 我是老麦， 一个小运维。 今天我们为 kustz 增加 service 解析功能。 通过 kubectl create service 命令可以看到， service 的模式还是挺多的。 1 2 3 4 5 6 7 8 9 10 11 $ kubectl create service -h Create a service using a specified subcommand. Aliases: service, svc Available Commands: clusterip Create a ClusterIP service externalname Create an ExternalName service loadbalancer Create a LoadBalancer service nodeport Create a NodePort service 除了以上列出来的四种之外， 还用一种 Headless Service( https://kubernetes.io/docs/concepts/services-networking/service/#headless-services )。 Headless Service 是当 类型 为 Clu</description></item><item><title>从零开始写 k8s 发布工具 - 2.3. 解析 URL 为 Ingress</title><link>https://tangx.in/posts/books/kustz/chapter02/03-parse-url-to-ingress/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter02/03-parse-url-to-ingress/</guid><description>2.3. 解析 URL 为 Ingress 之前已经提到过， 在 kustz.yml 中的字段值， 要尽量做到 见名知义。 对于 Ingress 而言， 在发布之后， 我们访问的就是 URL 地址。 http://api.example.com/v1 因此我们可以考虑 从结果推导解析渲染 Ingress 。 Kubernetes Ingress 老规矩， 我们还是通过命令看看创建一个 ingress 需要提供哪些参数。 1 2 $ kubectl create ingress simple --rule=&amp;#34;foo.com/bar=svc1:8080,tls=my-cert&amp;#34; -o yaml --dry-run=client 在 rule 中， 提供了两组 k-v。 其中， foo.com/bar 就是一个不带协</description></item><item><title>从零开始写 k8s 发布工具 - 2.4. 使用 kustomize 管理所有 k8s 文件</title><link>https://tangx.in/posts/books/kustz/chapter02/04-kustomize/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter02/04-kustomize/</guid><description>2.4. 使用 kustomize 管理所有 k8s 文件 前面已经简单的封装了 Deployment, Service, Ingress， 完成了零部件的创建。 今天就通过 Kustomization 进行组装， 实现流水线。 Kustomize 开始之前， 先来安装 kustomize 库。 1 $ go get sigs.k8s.io/kustomize/v3 这里补充一下， 访问 Github https://github.com/kubernetes-sigs/kustomize/ 。 kustomize () 首页 README.md 并没有提到 go get 的包名。 通常 k8s 的代码在 github 上都是镜像。 这时候只需要进到 go.mod ， 包名就一目了然。 1 2 3 4</description></item><item><title>从零开始写 k8s 发布工具 - 2.5. 使用 cobra 实现 kustz 命令</title><link>https://tangx.in/posts/books/kustz/chapter02/05-kustz-cli/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter02/05-kustz-cli/</guid><description>2.5. 使用 cobra 实现 kustz 命令 有了前面几章的努力， 我们的命令行工具 kustz 终于要问世了。 kustz 命令 当前命令功能就很简单。 default: 输出 kustz 默认配置。 render: 读取 kustz 配置并生成 kustomize 配置四件套。 1 2 3 4 5 $ kustz -h Available Commands: default 在屏幕上打印 kustz 默认配置 render 读取 kustz 配置， 生成 kustomize 所需文件 编码 本章的代码都很简单， 就是设计的文件比较多。 使用 cobra 创建命令</description></item><item><title>从零开始写 k8s 发布工具 - 3.1. 为 Container 添加环境变量</title><link>https://tangx.in/posts/books/kustz/chapter03/01-container-env-var/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/01-container-env-var/</guid><description>3.1. 为 Container 添加环境变量 再前面一章中， 我们已经完成了 Deployment, Service, Ingress 和 Kustomization API 的封装。 并通过 cobra 库创建了属于我们自己的 kustz 命令。 然而 kustz 的功能还简陋。 今天我们就先来为容器添加环境变量。 为容器设置环境变量 在官方文档中， 提高了两种为容器设置环境变量的方法 https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/ env: 提供 k-v 模式 键值对。 值可以直接 value 提供。 也可以通过 valueFrom 从 secret</description></item><item><title>从零开始写 k8s 发布工具 - 3.2. ConfigMap 和 Secret 的生成器</title><link>https://tangx.in/posts/books/kustz/chapter03/02-configmap-secret-generator/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/02-configmap-secret-generator/</guid><description>3.2. ConfigMap 和 Secret 的生成器 上一节我们通过 k-v 和 YAML文件 为容器添加环境变量。 同时也提到了可以通过 envFrom 这个关键字， 直接读取 ConfigMap 或 Secret 中的 k-v 作为容器的环境变量。 除了环境变量之外， ConfigMap 和 Secret 还能管理的东西还很多。 所以我个人觉得单应用管理部署的话， 对于配置的管理，还是比较重要的。 Kustomize 中的 ConfigMap Env File 在 kustzomize 中， ConfigMap 和 Secret 都</description></item><item><title>从零开始写 k8s 发布工具 - 3.3. 注入 ConfigMap 和 Secrets 到容器环境变量</title><link>https://tangx.in/posts/books/kustz/chapter03/03-container-env-from/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/03-container-env-from/</guid><description>3.3. 注入 ConfigMap 和 Secrets 到容器环境变量 大家好， 我是老麦。 一个运维小学生。 有了前面两张的铺垫， 今天这个很简单。 我们说说另外一种为容器注入环境变量的方式。 容器变量注入 EnvFrom 前面我们提到过， Container 有两种方式定义环境变量， 其中一种就是 envFrom， 从 ConfigMap 或 Secret 中读取所有键值对作为容器的变量。 ConfigMap 和 Secret 看起来是这样</description></item><item><title>从零开始写 k8s 发布工具 - 3.4. 用字符串定义容器申请资源上下限</title><link>https://tangx.in/posts/books/kustz/chapter03/04-container-resources/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/04-container-resources/</guid><description>3.4. 用字符串定义容器申请资源上下限 Pod 的资源申请， 在调度策略中， 是一个重要的参数数据。 因此其重要性自然不必多说 容器资源申请 在官网中， 对于资源的申请和管理有详细的描述。 https://kubernetes.io/zh-cn/docs/concepts/configuration/manage-resources-containers/ 和 服务质量 QoS 息息相关， https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/quality-service-pod/ 这里简单的归类， 可以速记， 按照服务质量高到低 Guaranteed: request = limit Burstable: request &amp;lt; limit BestEffort: 没有 request 和 limit kustz.yml 配置 还是先来看看 kustz.yml</description></item><item><title>从零开始写 k8s 发布工具 - 3.5. 为 Container 添加健康检查方法</title><link>https://tangx.in/posts/books/kustz/chapter03/05-container-probe/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/05-container-probe/</guid><description>3.5. 为 Container 添加健康检查方法 kustz 终于到了准生产的地步了。 今天的健康检查接口， 就为我们解决这个问题。 我们要知道， 确定一个应用能不能对外提供服务之前， 需要进行一个 可用性 检测。 而这个检测通常被我们称为 健康检查。 Kubernetes 的健康检查 在 Kubernetes 中， 为我们提供了 主要 的 3类状态 的健康检查。 startup: 等待探针。 如果执行成功，</description></item><item><title>从零开始写 k8s 发布工具 - 3.6. 镜像拉取鉴权和策略</title><link>https://tangx.in/posts/books/kustz/chapter03/06-image-pull-policy/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter03/06-image-pull-policy/</guid><description>3.6. 镜像拉取鉴权和策略 今天我们解决镜像拉取鉴权和策略 镜像拉取鉴权 拉取私有镜像或私有仓库镜像的时候， 需要提供鉴权信息。 在 Kubernets 中， 通过 Secret 管理账号这些账号信息。 Secret 类型分为两种， kubernetes.io/dockerconfigjson: 如果有linux安装了 docker， 就是 ~/.docker/config.json 这个文件。 kubernetes.io/dockercfg: 不太熟。 在 /pkg/tokube/pod.go 中， 可以看到 ImagePullSecrets 的处理方法。 就是将字符串转为 kubernetes 的</description></item><item><title>从零开始写 k8s 发布工具 - 4.1. 使用 cobrautils 为命令添加更实用的命令参数</title><link>https://tangx.in/posts/books/kustz/chapter04/01-kustz-flags/</link><pubDate>Thu, 05 Jan 2023 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/books/kustz/chapter04/01-kustz-flags/</guid><description>4.1. 使用 cobrautils 为命令添加更实用的命令参数 之前的章节， 我们陆陆续续给 kustz 库添加了很多丰富服务的配置 但 kustz 命令， 还是处于一个很原始的命令状态。 接下来我们给 kustz 添加一些更丰富的参数 ， 使 kustz 用起来更顺手。 在 CICD 的中， 一般情况下 变量，健康检查， 镜像策略 等很难发生变动。 而镜像名称 经常性 的在每次打包后发生变化</description></item><item><title>怎么在 Kustomize 中添加多行变量</title><link>https://tangx.in/posts/2023/01/05/how-to-create-multiple-line-variables-in-kustomize/</link><pubDate>Thu, 05 Jan 2023 13:09:55 +0800</pubDate><guid>https://tangx.in/posts/2023/01/05/how-to-create-multiple-line-variables-in-kustomize/</guid><description>怎么在 Kustomize 中添加多行变量 原文链接: https://tangx.in/posts/2023/01/05/how-to-create-multiple-line-variables-in-kustomize/ kustomize 是 k8s 官方出的一个 应用管理工具 ， 说起来还是很好用的。 可以参考 k8s 部署工具 kustomize 的实用小技巧 Kustomize 中的 ConfigMap/Secrets Generator 在配置管理方面， kustomize 为我们提供了 Generator 帮助我们管理配置文件。 提供了三个 API 模块 files: 通过 文件 生成 文件 literals: 通过文字 字面量 k=v 生成 k=v 数据 envs: 通过 文件 生成 k=v 数据。 这个应该是 files 和</description></item><item><title>Kubernetes 不同的升级策略是如何影响服务质量 QoS 的</title><link>https://tangx.in/posts/2023/01/03/kubernetes-upgrade-strategy-and-qos/</link><pubDate>Tue, 03 Jan 2023 18:15:50 +0800</pubDate><guid>https://tangx.in/posts/2023/01/03/kubernetes-upgrade-strategy-and-qos/</guid><description>Kubernetes 不同的升级策略是如何影响服务质量 QoS 的 Deployments#Strategy - Kubernetes 无论采取哪种升级方式, 都应该在容器中使用 probe , 降低业务抖动 Pod 升级策略 .spec.strategy.type 有两种方式可选: RollingUpdate : 滚动升级. .spec.strategy.rollingUpdate.maxUnavailable 最大不可用 , 默认 25% , 即升级期间, 总容器数量为 100%。 循环 删旧扩新 .spec.strategy.rollingUpdate.maxSurge 最大弹性, 默认 30% , 即升级期间, 总容器数量不超过 130%。 循环 扩新删旧</description></item></channel></rss>