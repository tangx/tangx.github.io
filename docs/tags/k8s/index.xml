<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>k8s on 老麦的书房</title><link>https://tangx.in/tags/k8s/</link><description>Recent content in k8s on 老麦的书房</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 02 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://tangx.in/tags/k8s/index.xml" rel="self" type="application/rss+xml"/><item><title>K8S 中被挂载的 Configmap 发生了变化容器内部会发生什么</title><link>https://tangx.in/posts/2021/12/02/configmap-mounting-scenario-when-updated/</link><pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/12/02/configmap-mounting-scenario-when-updated/</guid><description>K8S 中被挂载的 Configmap 发生了变化容器内部会发生什么 1. 使用 env 挂载 被挂载的值不会变 1 2 3 4 5 6 7 env: # 定义环境变量 - name: PLAYER_INITIAL_LIVES # 请注意这里和 ConfigMap 中的键名是不一样的 valueFrom: configMapKeyRef: name: game-demo # 这个值来自 ConfigMap key: player_initial_lives # 需要取值的键 使用 volumeMounts 挂载目录 在使用 volumeMounts 挂载的时候， 根据是否有 subpath 参数， 情况也不一样。 2.1 没有 subpath 挂载目录 1 2 3 volumeMounts: - name: config mountPath: &amp;#34;/config/normal-dir/some-path/&amp;#34;</description></item><item><title>K8S 使用 TTL 控制器自动清理完成的 job pod</title><link>https://tangx.in/posts/2021/09/23/k8s-ttl-seconds-after-finished-forbidden/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/09/23/k8s-ttl-seconds-after-finished-forbidden/</guid><description>K8S 使用 TTL 控制器自动清理完成的 Job Pod 最近为集群 CI 默认添加了 .spec.ttlSecondsAfterFinished 参数， 以便在 cronjob 和 job 运行完成后自动清理过期 pod 。 但是在 CI 的时候却失败， 报错如下。 1 spec.jobTemplate.spec.ttlSecondsAfterFinished: Forbidden: disabled by feature-gate 核查资料得知， 在 v1.21 之前， 该开关默认是关闭的。 刚好错误集群低于此版本。 Job TTL 控制器 K8S 提供了一个 TTL 控制器， 可以自动在 JOB Complete 或 Failed 之后， 经过一定时间</description></item><item><title>5分钟k3s-什么是 K3s? K3s 简介与适用场景介绍</title><link>https://tangx.in/posts/2021/06/05/k3s-introduce/</link><pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/06/05/k3s-introduce/</guid><description>什么是 K3s? K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。 K3s 有以下增强功能： 打包为单个二进制文件。 使用基于 sqlite3 的轻量级存储后端作为默认存储机制。同时支持使用 etcd3、MySQL 和 + PostgreSQL 作为存储机制。 封装在简单的启动程序中，通过该启动程序处理很多复杂的 TLS 和选项。 默</description></item><item><title>CronJob 和 Job 的 退出 POD 数量管理</title><link>https://tangx.in/posts/2021/01/22/exited-pod-limits/</link><pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2021/01/22/exited-pod-limits/</guid><description>CronJob 和 Job 的 Pod 退出保留时间 cronjob 可以认为 CronJob 作为定时调度器， 在正确的时间创建 Job Pod 完成任务。 在 CronJob 中， 默认 .spec.successfulJobsHistoryLimit: 保留 3 个正常退出的 Job .spec.failedJobsHistoryLimit: 1 个异常退出的 Job 1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: batch/v1beta1 kind: CronJob metadata: name: zeus-cron-checkqueue namespace: zeus-dev spec: schedule: &amp;#34;*/10 * * * *&amp;#34; failedJobsHistoryLimit: 1 successfulJobsHistoryLimit: 3 jobTemplate: spec: template: # ... 略 https://github.com/kubernetes/kubernetes/issues/64056 job 除了 cronjob 管理 job 之外， job 本身也提供 .spec.ttlSecondsAfterFinished 进行退出管理。 默认情况下 如果 ttlSecondsAfterFinished 值未</description></item><item><title>k8s 部署工具 kustomize 的实用小技巧</title><link>https://tangx.in/posts/2020/12/05/kusutomize-usage-tips/</link><pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2020/12/05/kusutomize-usage-tips/</guid><description>k8s 部署工具 kustomize 的实用小技巧 在 k8s 上的部署， 大多组件都默认提供 helm 方式。 在实际使用中， 常常需要针对不通环境进行差异化配置。 个人觉得， 使用 kustomize 替换在使用和管理上，比直接使用 helm 参数更为清晰 。 同时组件在一个大版本下的部署方式通常不会有太大的变化， 没有必要重新维护一套部署文档，其实也不一定有精力这</description></item><item><title>calico 配置 BGP Route Reflectors</title><link>https://tangx.in/posts/2019/12/10/calico-bgp-rr/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/12/10/calico-bgp-rr/</guid><description>calico 配置 BGP Route Reflectors Calico作为k8s的一个流行网络插件，它依赖BGP路由协议实现集群节点上的POD路由互通；而路由互通的前提是节点间建立 BGP Peer 连接。BGP 路由反射器（Route Reflectors，简称 RR）可以简化集群BGP Peer的连接方式，它是解决BGP扩展性问题的有效方式；具</description></item><item><title>calico 网络模型的简单笔记</title><link>https://tangx.in/posts/2019/11/26/calico-simple-note/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/11/26/calico-simple-note/</guid><description>calico 简单笔记 calico 是一种基础 vRouter 的3层网络模型 (BGP 网络)。 在应用到 k8s 中，可以提到常见的 flannel。 使用节点主机作为 vRouter 实现 3层转发。 提高网络性能。 calico 的网络模型 calico 可以通过设置 IP-in-IP 控制网络模型: https://docs.projectcalico.org/v3.5/usage/configuration/ip-in-ip ipipMode=Never: BGP 模型。 完全不使用 IP-in-IP 隧道， 这就是常用的 BGP 模型。 ipipMode=Always: calico 节点直接通过 IP 隧道的的方式实现节点互通。 这实际</description></item><item><title>k8s nginx ingress 添加 x-forwarded</title><link>https://tangx.in/posts/2019/08/10/nginx-ingress-x-forward/</link><pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2019/08/10/nginx-ingress-x-forward/</guid><description>ingress 配置 for-forward-for The client IP address will be set based on the use of PROXY protocol or from the X-Forwarded-For header value when use-forwarded-headers is enabled. https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#forwarded-for-header 1 2 3 4 5 6 7 8 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: srv-bff-op-center annotations: nginx.ingress.kubernetes.io/forwarded-for-header: &amp;#34;X-Forwarded-For&amp;#34; kubernetes.io/ingress.class: &amp;#34;nginx&amp;#34;</description></item><item><title>K8S 中使用 Heketi 管理 GlusterFS</title><link>https://tangx.in/posts/2018/11/15/k8s-with-heketi/</link><pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/11/15/k8s-with-heketi/</guid><description>K8S 中使用 Heketi 管理 GlusterFS 与 官方文档不同 ， 本文中的 glusterfs 是独立与 k8s 之外的。 Heketi heketi 项目 为 GlusterFS 提供 RESTful 的 API 管理。 Requirements System must have glusterd service enabled and glusterfs-server installed Disks registered with Heketi must be in raw format. 目前提供两种管理方式: ssh, kubernetes heketi-ssh SSH Access SSH user and public key already setup on the node SSH user must have password-less sudo Must be able to run sudo commands from ssh. This requires disabling requiretty in the /etc/sudoers file 使用容器部署 https://hub.docker.com/r/heketi/heketi/ heketi-kubernetes 带实现 勘误 在使用 K8S 部署时， 如果客户端报错</description></item><item><title>K8S节点下载 gcr.io 原生镜像</title><link>https://tangx.in/posts/2018/11/09/k8s-pull-image-from-gcr.io/</link><pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/11/09/k8s-pull-image-from-gcr.io/</guid><description>K8S下载 gcr.io 原生镜像 在国内是不能直接下载 gcr.io / k8s.gcr.io 等原生镜像的。 使用比较权威的三方源 aliyun , qcloud 将 gcr.io push 到 hub.docker.com 自建镜像代理 域名翻墙 域名翻墙 通过域名劫持，将目标地址直接解析到代理服务器上。 sniproxy 所有你需要的， 一个能直接访问 gcr.ip 的 https(443) 代理。 通过 sniproxy 实现。 通过 防火墙 , 安全组 限制访问来源。 1 2 # docker run -d --rm --network host --name sniproxy</description></item><item><title>k8s node 节点</title><link>https://tangx.in/posts/2018/10/13/k8s-resource-node.md/</link><pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/13/k8s-resource-node.md/</guid><description>k8s node 节点介绍 node 是 k8s 的工作节点， cpu, memory 的提供者。 上面运行这实际工作的 pod。 node 的服务包括 container 环境、 kubelet 和 kube-proxy。 使用 kubectl 管理 node 基础语法为 : kubectl flag node &amp;lt;node_name&amp;gt; kubectl cordon / uncordon 1 2 3 4 # 驱逐 kubectl cordon node &amp;lt;node_name&amp;gt; # 恢复 kubectl uncordon node &amp;lt;node_name&amp;gt;</description></item><item><title>kubernetes POD 介绍</title><link>https://tangx.in/posts/2018/10/13/k8s-object-pod.md/</link><pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate><guid>https://tangx.in/posts/2018/10/13/k8s-object-pod.md/</guid><description>k8s POD 介绍 POD 在 k8s 中是最小管理单位。</description></item></channel></rss>